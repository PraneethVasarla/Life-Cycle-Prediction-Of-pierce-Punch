{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('train.xlsx')\n",
    "test = pd.read_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(train.drop(['Cycles'], 1))\n",
    "y = np.array(train['Cycles'])\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE EMPTY NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(128,name = 'InputLayer', kernel_initializer='normal',input_dim = X.shape[1], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(256,name = '1stHiddenLayer', kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256,name = '2ndHiddenLayer', kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256,name = '3rdHiddenLayer', kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(1,name = 'OutputLayer', kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function used is mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "InputLayer (Dense)           (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "1stHiddenLayer (Dense)       (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "2ndHiddenLayer (Dense)       (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "3rdHiddenLayer (Dense)       (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,273\n",
      "Trainable params: 166,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the NN and creating checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights.best.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained with 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 538 samples, validate on 135 samples\n",
      "Epoch 1/500\n",
      "538/538 [==============================] - 8s 15ms/step - loss: 55925.3865 - acc: 0.0000e+00 - val_loss: 11291.4979 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 163.86435\n",
      "Epoch 2/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 58841.2170 - acc: 0.0000e+00 - val_loss: 3280.2838 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 163.86435\n",
      "Epoch 3/500\n",
      "538/538 [==============================] - 0s 236us/step - loss: 54193.1479 - acc: 0.0000e+00 - val_loss: 984.9069 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 163.86435\n",
      "Epoch 4/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 54615.3457 - acc: 0.0000e+00 - val_loss: 9224.8176 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 163.86435\n",
      "Epoch 5/500\n",
      "538/538 [==============================] - 0s 264us/step - loss: 52680.5714 - acc: 0.0000e+00 - val_loss: 30165.1740 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 163.86435\n",
      "Epoch 6/500\n",
      "538/538 [==============================] - 0s 236us/step - loss: 58199.2797 - acc: 0.0000e+00 - val_loss: 4377.5600 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 163.86435\n",
      "Epoch 7/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 56079.2493 - acc: 0.0000e+00 - val_loss: 7146.8356 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 163.86435\n",
      "Epoch 8/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 54915.0674 - acc: 0.0000e+00 - val_loss: 15096.8037 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 163.86435\n",
      "Epoch 9/500\n",
      "538/538 [==============================] - 0s 240us/step - loss: 59471.6588 - acc: 0.0000e+00 - val_loss: 36901.9181 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 163.86435\n",
      "Epoch 10/500\n",
      "538/538 [==============================] - 0s 268us/step - loss: 56939.6610 - acc: 0.0000e+00 - val_loss: 18008.2910 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 163.86435\n",
      "Epoch 11/500\n",
      "538/538 [==============================] - ETA: 0s - loss: 52898.8047 - acc: 0.0000e+0 - 0s 214us/step - loss: 52731.7135 - acc: 0.0000e+00 - val_loss: 3349.5738 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 163.86435\n",
      "Epoch 12/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 56185.7959 - acc: 0.0000e+00 - val_loss: 5697.2377 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 163.86435\n",
      "Epoch 13/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 57126.2669 - acc: 0.0000e+00 - val_loss: 20314.8496 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 163.86435\n",
      "Epoch 14/500\n",
      "538/538 [==============================] - ETA: 0s - loss: 64317.8453 - acc: 0.0000e+0 - 0s 316us/step - loss: 61905.3325 - acc: 0.0000e+00 - val_loss: 20031.9479 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 163.86435\n",
      "Epoch 15/500\n",
      "538/538 [==============================] - 0s 286us/step - loss: 51853.3398 - acc: 0.0000e+00 - val_loss: 4468.2512 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 163.86435\n",
      "Epoch 16/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 56687.8982 - acc: 0.0000e+00 - val_loss: 31830.8314 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 163.86435\n",
      "Epoch 17/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 62881.2749 - acc: 0.0000e+00 - val_loss: 13301.0069 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 163.86435\n",
      "Epoch 18/500\n",
      "538/538 [==============================] - 0s 275us/step - loss: 59734.8867 - acc: 0.0000e+00 - val_loss: 20533.6287 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 163.86435\n",
      "Epoch 19/500\n",
      "538/538 [==============================] - 0s 258us/step - loss: 54117.6727 - acc: 0.0000e+00 - val_loss: 6202.5227 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 163.86435\n",
      "Epoch 20/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 54719.8984 - acc: 0.0000e+00 - val_loss: 11216.3667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 163.86435\n",
      "Epoch 21/500\n",
      "538/538 [==============================] - 0s 207us/step - loss: 54466.2088 - acc: 0.0000e+00 - val_loss: 11547.9671 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 163.86435\n",
      "Epoch 22/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 54251.9596 - acc: 0.0000e+00 - val_loss: 1151.0215 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 163.86435\n",
      "Epoch 23/500\n",
      "538/538 [==============================] - 0s 233us/step - loss: 54150.0017 - acc: 0.0000e+00 - val_loss: 6743.4965 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 163.86435\n",
      "Epoch 24/500\n",
      "538/538 [==============================] - 0s 307us/step - loss: 55672.2384 - acc: 0.0000e+00 - val_loss: 12226.3456 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 163.86435\n",
      "Epoch 25/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 54099.5500 - acc: 0.0000e+00 - val_loss: 14527.6787 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 163.86435\n",
      "Epoch 26/500\n",
      "538/538 [==============================] - 0s 329us/step - loss: 54951.8278 - acc: 0.0000e+00 - val_loss: 18017.9625 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 163.86435\n",
      "Epoch 27/500\n",
      "538/538 [==============================] - 0s 277us/step - loss: 53325.3267 - acc: 0.0000e+00 - val_loss: 10104.5271 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 163.86435\n",
      "Epoch 28/500\n",
      "538/538 [==============================] - 0s 281us/step - loss: 53873.7098 - acc: 0.0000e+00 - val_loss: 12597.1697 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 163.86435\n",
      "Epoch 29/500\n",
      "538/538 [==============================] - 0s 269us/step - loss: 52763.0949 - acc: 0.0000e+00 - val_loss: 12155.4692 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 163.86435\n",
      "Epoch 30/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 51761.4625 - acc: 0.0000e+00 - val_loss: 15022.3928 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 163.86435\n",
      "Epoch 31/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 51575.1918 - acc: 0.0000e+00 - val_loss: 25258.0175 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 163.86435\n",
      "Epoch 32/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 57330.8337 - acc: 0.0000e+00 - val_loss: 8125.2806 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 163.86435\n",
      "Epoch 33/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 53545.2351 - acc: 0.0000e+00 - val_loss: 27713.0792 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 163.86435\n",
      "Epoch 34/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 52344.7924 - acc: 0.0000e+00 - val_loss: 8881.7667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 163.86435\n",
      "Epoch 35/500\n",
      "538/538 [==============================] - 0s 241us/step - loss: 54050.5140 - acc: 0.0000e+00 - val_loss: 1030.2285 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 163.86435\n",
      "Epoch 36/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 48846.0357 - acc: 0.0000e+00 - val_loss: 13036.6731 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 163.86435\n",
      "Epoch 37/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 56641.0874 - acc: 0.0000e+00 - val_loss: 4904.8678 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 163.86435\n",
      "Epoch 38/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 53358.6124 - acc: 0.0000e+00 - val_loss: 6153.5836 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 163.86435\n",
      "Epoch 39/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 57578.8367 - acc: 0.0000e+00 - val_loss: 16414.6996 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 163.86435\n",
      "Epoch 40/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 52996.7115 - acc: 0.0000e+00 - val_loss: 5935.5512 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 163.86435\n",
      "Epoch 41/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 51240.3444 - acc: 0.0000e+00 - val_loss: 1531.6069 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 163.86435\n",
      "Epoch 42/500\n",
      "538/538 [==============================] - 0s 308us/step - loss: 52519.7778 - acc: 0.0000e+00 - val_loss: 10474.0322 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 163.86435\n",
      "Epoch 43/500\n",
      "538/538 [==============================] - 0s 312us/step - loss: 57624.4087 - acc: 0.0000e+00 - val_loss: 5987.5259 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 163.86435\n",
      "Epoch 44/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 53981.3180 - acc: 0.0000e+00 - val_loss: 20214.8412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 163.86435\n",
      "Epoch 45/500\n",
      "538/538 [==============================] - 0s 247us/step - loss: 58381.0423 - acc: 0.0000e+00 - val_loss: 7645.9211 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 163.86435\n",
      "Epoch 46/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 58084.7458 - acc: 0.0000e+00 - val_loss: 23397.6414 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 163.86435\n",
      "Epoch 47/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 56756.8221 - acc: 0.0000e+00 - val_loss: 5319.8109 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 163.86435\n",
      "Epoch 48/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 56873.4399 - acc: 0.0000e+00 - val_loss: 8232.4963 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 163.86435\n",
      "Epoch 49/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 57120.9399 - acc: 0.0000e+00 - val_loss: 23016.2919 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 163.86435\n",
      "Epoch 50/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 54299.1414 - acc: 0.0000e+00 - val_loss: 14069.3440 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 163.86435\n",
      "Epoch 51/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 55755.8341 - acc: 0.0000e+00 - val_loss: 3344.1602 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 163.86435\n",
      "Epoch 52/500\n",
      "538/538 [==============================] - 0s 236us/step - loss: 53299.1366 - acc: 0.0000e+00 - val_loss: 6528.6685 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 163.86435\n",
      "Epoch 53/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 54517.3153 - acc: 0.0000e+00 - val_loss: 17688.6940 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 163.86435\n",
      "Epoch 54/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 56904.0048 - acc: 0.0000e+00 - val_loss: 7434.2220 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 163.86435\n",
      "Epoch 55/500\n",
      "538/538 [==============================] - 0s 286us/step - loss: 53138.2164 - acc: 0.0000e+00 - val_loss: 11674.8109 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 163.86435\n",
      "Epoch 56/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 55996.1355 - acc: 0.0000e+00 - val_loss: 2467.0185 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 163.86435\n",
      "Epoch 57/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 57963.2463 - acc: 0.0000e+00 - val_loss: 3008.5257 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 163.86435\n",
      "Epoch 58/500\n",
      "538/538 [==============================] - 0s 265us/step - loss: 54175.2538 - acc: 0.0000e+00 - val_loss: 7260.9178 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 163.86435\n",
      "Epoch 59/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 53203.8624 - acc: 0.0000e+00 - val_loss: 11757.3229 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 163.86435\n",
      "Epoch 60/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 52131.0238 - acc: 0.0000e+00 - val_loss: 3910.4655 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 163.86435\n",
      "Epoch 61/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 60161.5447 - acc: 0.0000e+00 - val_loss: 39974.7580 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 163.86435\n",
      "Epoch 62/500\n",
      "538/538 [==============================] - 0s 189us/step - loss: 55722.6480 - acc: 0.0000e+00 - val_loss: 21205.3970 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 163.86435\n",
      "Epoch 63/500\n",
      "538/538 [==============================] - 0s 241us/step - loss: 55364.0194 - acc: 0.0000e+00 - val_loss: 8008.8454 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 163.86435\n",
      "Epoch 64/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 52102.7226 - acc: 0.0000e+00 - val_loss: 8708.4998 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 163.86435\n",
      "Epoch 65/500\n",
      "538/538 [==============================] - 0s 236us/step - loss: 55843.4927 - acc: 0.0000e+00 - val_loss: 17760.6088 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 163.86435\n",
      "Epoch 66/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 53158.8857 - acc: 0.0000e+00 - val_loss: 8715.9775 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 163.86435\n",
      "Epoch 67/500\n",
      "538/538 [==============================] - 0s 241us/step - loss: 56165.5704 - acc: 0.0000e+00 - val_loss: 33546.3343 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 163.86435\n",
      "Epoch 68/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 57219.9995 - acc: 0.0000e+00 - val_loss: 11813.7842 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 163.86435\n",
      "Epoch 69/500\n",
      "538/538 [==============================] - 0s 240us/step - loss: 53173.2198 - acc: 0.0000e+00 - val_loss: 2230.1843 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 163.86435\n",
      "Epoch 70/500\n",
      "538/538 [==============================] - 0s 279us/step - loss: 52303.5855 - acc: 0.0000e+00 - val_loss: 10149.5373 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 163.86435\n",
      "Epoch 71/500\n",
      "538/538 [==============================] - 0s 256us/step - loss: 54114.1644 - acc: 0.0000e+00 - val_loss: 9682.6736 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 163.86435\n",
      "Epoch 72/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 56071.9158 - acc: 0.0000e+00 - val_loss: 3134.4063 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 163.86435\n",
      "Epoch 73/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 59281.4945 - acc: 0.0000e+00 - val_loss: 24208.3595 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 163.86435\n",
      "Epoch 74/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 56811.9910 - acc: 0.0000e+00 - val_loss: 4279.8338 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 163.86435\n",
      "Epoch 75/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 56736.3271 - acc: 0.0000e+00 - val_loss: 28804.0965 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 163.86435\n",
      "Epoch 76/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 56603.9146 - acc: 0.0000e+00 - val_loss: 15795.5724 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 163.86435\n",
      "Epoch 77/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 54691.0989 - acc: 0.0000e+00 - val_loss: 4734.3488 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 163.86435\n",
      "Epoch 78/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 52368.2338 - acc: 0.0000e+00 - val_loss: 11257.1553 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 163.86435\n",
      "Epoch 79/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 56821.7970 - acc: 0.0000e+00 - val_loss: 9209.2111 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 163.86435\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 249us/step - loss: 56872.1192 - acc: 0.0000e+00 - val_loss: 1536.4810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 163.86435\n",
      "Epoch 81/500\n",
      "538/538 [==============================] - 0s 244us/step - loss: 55116.7656 - acc: 0.0000e+00 - val_loss: 8014.8400 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 163.86435\n",
      "Epoch 82/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 56520.0046 - acc: 0.0000e+00 - val_loss: 12205.0201 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 163.86435\n",
      "Epoch 83/500\n",
      "538/538 [==============================] - 0s 281us/step - loss: 59236.3017 - acc: 0.0000e+00 - val_loss: 5459.2845 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 163.86435\n",
      "Epoch 84/500\n",
      "538/538 [==============================] - 0s 279us/step - loss: 51980.4430 - acc: 0.0000e+00 - val_loss: 15000.9831 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 163.86435\n",
      "Epoch 85/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 53939.3923 - acc: 0.0000e+00 - val_loss: 6661.9924 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 163.86435\n",
      "Epoch 86/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 56680.5739 - acc: 0.0000e+00 - val_loss: 1435.6988 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 163.86435\n",
      "Epoch 87/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 54160.7476 - acc: 0.0000e+00 - val_loss: 2660.2174 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 163.86435\n",
      "Epoch 88/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 54071.6692 - acc: 0.0000e+00 - val_loss: 16517.8199 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 163.86435\n",
      "Epoch 89/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 54742.5526 - acc: 0.0000e+00 - val_loss: 9504.1090 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 163.86435\n",
      "Epoch 90/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 55315.2317 - acc: 0.0000e+00 - val_loss: 12220.1361 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 163.86435\n",
      "Epoch 91/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 52094.5278 - acc: 0.0000e+00 - val_loss: 9868.8954 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 163.86435\n",
      "Epoch 92/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 54965.2204 - acc: 0.0000e+00 - val_loss: 25459.1167 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 163.86435\n",
      "Epoch 93/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 54702.2249 - acc: 0.0000e+00 - val_loss: 15352.7225 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 163.86435\n",
      "Epoch 94/500\n",
      "538/538 [==============================] - 0s 273us/step - loss: 55040.7579 - acc: 0.0000e+00 - val_loss: 4767.9035 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 163.86435\n",
      "Epoch 95/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 52875.2779 - acc: 0.0000e+00 - val_loss: 9323.7118 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 163.86435\n",
      "Epoch 96/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 58299.4788 - acc: 0.0000e+00 - val_loss: 16293.8185 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 163.86435\n",
      "Epoch 97/500\n",
      "538/538 [==============================] - 0s 303us/step - loss: 55689.6985 - acc: 0.0000e+00 - val_loss: 9381.9949 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 163.86435\n",
      "Epoch 98/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 53960.3626 - acc: 0.0000e+00 - val_loss: 14604.1680 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 163.86435\n",
      "Epoch 99/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 52235.1133 - acc: 0.0000e+00 - val_loss: 7566.9141 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 163.86435\n",
      "Epoch 100/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 55013.6527 - acc: 0.0000e+00 - val_loss: 19435.4505 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 163.86435\n",
      "Epoch 101/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 56439.4312 - acc: 0.0000e+00 - val_loss: 4459.4775 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 163.86435\n",
      "Epoch 102/500\n",
      "538/538 [==============================] - 0s 207us/step - loss: 54375.3188 - acc: 0.0000e+00 - val_loss: 30345.7347 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 163.86435\n",
      "Epoch 103/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 56395.9881 - acc: 0.0000e+00 - val_loss: 7891.8287 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 163.86435\n",
      "Epoch 104/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 55623.5738 - acc: 0.0000e+00 - val_loss: 12774.5544 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 163.86435\n",
      "Epoch 105/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 54093.8259 - acc: 0.0000e+00 - val_loss: 10777.9435 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 163.86435\n",
      "Epoch 106/500\n",
      "538/538 [==============================] - 0s 241us/step - loss: 57441.7630 - acc: 0.0000e+00 - val_loss: 2402.5514 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 163.86435\n",
      "Epoch 107/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 54058.8314 - acc: 0.0000e+00 - val_loss: 22628.7674 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 163.86435\n",
      "Epoch 108/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 55187.6915 - acc: 0.0000e+00 - val_loss: 20826.0894 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 163.86435\n",
      "Epoch 109/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 53144.3223 - acc: 0.0000e+00 - val_loss: 15842.1361 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 163.86435\n",
      "Epoch 110/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 55830.3353 - acc: 0.0000e+00 - val_loss: 11041.2768 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 163.86435\n",
      "Epoch 111/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 55209.9158 - acc: 0.0000e+00 - val_loss: 1200.4539 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 163.86435\n",
      "Epoch 112/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 57264.7101 - acc: 0.0000e+00 - val_loss: 10761.2185 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 163.86435\n",
      "Epoch 113/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 58089.0494 - acc: 0.0000e+00 - val_loss: 24411.0645 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 163.86435\n",
      "Epoch 114/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 54426.1166 - acc: 0.0000e+00 - val_loss: 8214.2352 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 163.86435\n",
      "Epoch 115/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 55247.1719 - acc: 0.0000e+00 - val_loss: 16155.3183 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 163.86435\n",
      "Epoch 116/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 57394.3346 - acc: 0.0000e+00 - val_loss: 9263.3005 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 163.86435\n",
      "Epoch 117/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 57270.6520 - acc: 0.0000e+00 - val_loss: 7893.4803 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 163.86435\n",
      "Epoch 118/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 55532.2114 - acc: 0.0000e+00 - val_loss: 10937.3278 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 163.86435\n",
      "Epoch 119/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 55526.6073 - acc: 0.0000e+00 - val_loss: 5772.3838 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 163.86435\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 219us/step - loss: 55919.1034 - acc: 0.0000e+00 - val_loss: 6032.5368 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 163.86435\n",
      "Epoch 121/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 53962.5117 - acc: 0.0000e+00 - val_loss: 10017.8456 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 163.86435\n",
      "Epoch 122/500\n",
      "538/538 [==============================] - 0s 255us/step - loss: 57234.3227 - acc: 0.0000e+00 - val_loss: 6243.6864 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 163.86435\n",
      "Epoch 123/500\n",
      "538/538 [==============================] - 0s 240us/step - loss: 57761.6857 - acc: 0.0000e+00 - val_loss: 8919.3250 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 163.86435\n",
      "Epoch 124/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 53052.4218 - acc: 0.0000e+00 - val_loss: 9165.3074 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 163.86435\n",
      "Epoch 125/500\n",
      "538/538 [==============================] - 0s 197us/step - loss: 57022.7496 - acc: 0.0000e+00 - val_loss: 10913.0482 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 163.86435\n",
      "Epoch 126/500\n",
      "538/538 [==============================] - 0s 273us/step - loss: 54114.9416 - acc: 0.0000e+00 - val_loss: 8627.0400 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 163.86435\n",
      "Epoch 127/500\n",
      "538/538 [==============================] - 0s 273us/step - loss: 54874.3041 - acc: 0.0000e+00 - val_loss: 6549.4854 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 163.86435\n",
      "Epoch 128/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 55608.4851 - acc: 0.0000e+00 - val_loss: 726.0285 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 163.86435\n",
      "Epoch 129/500\n",
      "538/538 [==============================] - 0s 273us/step - loss: 55672.1672 - acc: 0.0000e+00 - val_loss: 953.5544 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 163.86435\n",
      "Epoch 130/500\n",
      "538/538 [==============================] - 0s 196us/step - loss: 51741.8342 - acc: 0.0000e+00 - val_loss: 6212.4042 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 163.86435\n",
      "Epoch 131/500\n",
      "538/538 [==============================] - 0s 261us/step - loss: 57509.2301 - acc: 0.0000e+00 - val_loss: 23834.1673 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 163.86435\n",
      "Epoch 132/500\n",
      "538/538 [==============================] - 0s 282us/step - loss: 58209.9617 - acc: 0.0000e+00 - val_loss: 6116.8021 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 163.86435\n",
      "Epoch 133/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 52655.3885 - acc: 0.0000e+00 - val_loss: 17955.1215 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 163.86435\n",
      "Epoch 134/500\n",
      "538/538 [==============================] - 0s 267us/step - loss: 55637.0592 - acc: 0.0000e+00 - val_loss: 3466.7694 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 163.86435\n",
      "Epoch 135/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 55815.6125 - acc: 0.0000e+00 - val_loss: 13071.6785 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 163.86435\n",
      "Epoch 136/500\n",
      "538/538 [==============================] - 0s 253us/step - loss: 56739.7773 - acc: 0.0000e+00 - val_loss: 9777.3461 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 163.86435\n",
      "Epoch 137/500\n",
      "538/538 [==============================] - 0s 303us/step - loss: 53831.3420 - acc: 0.0000e+00 - val_loss: 9359.7986 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 163.86435\n",
      "Epoch 138/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 56117.7231 - acc: 0.0000e+00 - val_loss: 9618.6664 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 163.86435\n",
      "Epoch 139/500\n",
      "538/538 [==============================] - ETA: 0s - loss: 54863.5820 - acc: 0.0000e+0 - 0s 251us/step - loss: 55424.5410 - acc: 0.0000e+00 - val_loss: 18864.3261 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 163.86435\n",
      "Epoch 140/500\n",
      "538/538 [==============================] - 0s 271us/step - loss: 57092.9858 - acc: 0.0000e+00 - val_loss: 14283.6880 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 163.86435\n",
      "Epoch 141/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 58819.0957 - acc: 0.0000e+00 - val_loss: 12852.7262 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 163.86435\n",
      "Epoch 142/500\n",
      "538/538 [==============================] - 0s 260us/step - loss: 55150.7985 - acc: 0.0000e+00 - val_loss: 6951.9086 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 163.86435\n",
      "Epoch 143/500\n",
      "538/538 [==============================] - 0s 224us/step - loss: 54056.2382 - acc: 0.0000e+00 - val_loss: 11103.8952 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 163.86435\n",
      "Epoch 144/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 55816.2236 - acc: 0.0000e+00 - val_loss: 14625.1062 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 163.86435\n",
      "Epoch 145/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 56340.3141 - acc: 0.0000e+00 - val_loss: 11646.7345 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 163.86435\n",
      "Epoch 146/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 55931.9862 - acc: 0.0000e+00 - val_loss: 2409.7514 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 163.86435\n",
      "Epoch 147/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 51984.7633 - acc: 0.0000e+00 - val_loss: 1851.7528 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 163.86435\n",
      "Epoch 148/500\n",
      "538/538 [==============================] - 0s 240us/step - loss: 51392.7455 - acc: 0.0000e+00 - val_loss: 14389.1544 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 163.86435\n",
      "Epoch 149/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 54489.9444 - acc: 0.0000e+00 - val_loss: 6063.5854 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 163.86435\n",
      "Epoch 150/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 54797.2517 - acc: 0.0000e+00 - val_loss: 8635.6292 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 163.86435\n",
      "Epoch 151/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 53078.3580 - acc: 0.0000e+00 - val_loss: 16353.2303 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 163.86435\n",
      "Epoch 152/500\n",
      "538/538 [==============================] - 0s 232us/step - loss: 52074.0090 - acc: 0.0000e+00 - val_loss: 5627.3606 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 163.86435\n",
      "Epoch 153/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 56661.9450 - acc: 0.0000e+00 - val_loss: 25361.3419 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 163.86435\n",
      "Epoch 154/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 55831.6154 - acc: 0.0000e+00 - val_loss: 1446.7859 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 163.86435\n",
      "Epoch 155/500\n",
      "538/538 [==============================] - 0s 269us/step - loss: 53554.6701 - acc: 0.0000e+00 - val_loss: 1835.6442 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 163.86435\n",
      "Epoch 156/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 56011.7549 - acc: 0.0000e+00 - val_loss: 22609.2734 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 163.86435\n",
      "Epoch 157/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 55120.8557 - acc: 0.0000e+00 - val_loss: 11078.7743 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 163.86435\n",
      "Epoch 158/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 53796.4993 - acc: 0.0000e+00 - val_loss: 12867.8326 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 163.86435\n",
      "Epoch 159/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 58150.3636 - acc: 0.0000e+00 - val_loss: 1160.5167 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00159: val_loss did not improve from 163.86435\n",
      "Epoch 160/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 55155.2728 - acc: 0.0000e+00 - val_loss: 24187.9673 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 163.86435\n",
      "Epoch 161/500\n",
      "538/538 [==============================] - 0s 258us/step - loss: 57277.9645 - acc: 0.0000e+00 - val_loss: 26386.8377 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 163.86435\n",
      "Epoch 162/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 57021.7445 - acc: 0.0000e+00 - val_loss: 19154.5449 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 163.86435\n",
      "Epoch 163/500\n",
      "538/538 [==============================] - 0s 294us/step - loss: 57461.0820 - acc: 0.0000e+00 - val_loss: 21281.2405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 163.86435\n",
      "Epoch 164/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 55721.2190 - acc: 0.0000e+00 - val_loss: 10580.9081 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 163.86435\n",
      "Epoch 165/500\n",
      "538/538 [==============================] - 0s 276us/step - loss: 53442.6128 - acc: 0.0000e+00 - val_loss: 13223.3250 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 163.86435\n",
      "Epoch 166/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 55958.3461 - acc: 0.0000e+00 - val_loss: 21007.0745 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 163.86435\n",
      "Epoch 167/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 53687.5362 - acc: 0.0000e+00 - val_loss: 4440.5706 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 163.86435\n",
      "Epoch 168/500\n",
      "538/538 [==============================] - 0s 279us/step - loss: 51281.3281 - acc: 0.0000e+00 - val_loss: 1315.7252 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 163.86435\n",
      "Epoch 169/500\n",
      "538/538 [==============================] - 0s 260us/step - loss: 60343.9330 - acc: 0.0000e+00 - val_loss: 9789.4317 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 163.86435\n",
      "Epoch 170/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 55989.8775 - acc: 0.0000e+00 - val_loss: 3752.3894 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 163.86435\n",
      "Epoch 171/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 57622.3383 - acc: 0.0000e+00 - val_loss: 18690.8627 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 163.86435\n",
      "Epoch 172/500\n",
      "538/538 [==============================] - 0s 271us/step - loss: 55662.8909 - acc: 0.0000e+00 - val_loss: 12786.5192 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 163.86435\n",
      "Epoch 173/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 57798.3498 - acc: 0.0000e+00 - val_loss: 6499.6440 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 163.86435\n",
      "Epoch 174/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 53147.3841 - acc: 0.0000e+00 - val_loss: 30414.1588 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 163.86435\n",
      "Epoch 175/500\n",
      "538/538 [==============================] - 0s 192us/step - loss: 53811.6130 - acc: 0.0000e+00 - val_loss: 11849.9685 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 163.86435\n",
      "Epoch 176/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 56992.0669 - acc: 0.0000e+00 - val_loss: 21010.5820 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 163.86435\n",
      "Epoch 177/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 53863.1009 - acc: 0.0000e+00 - val_loss: 7586.4465 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 163.86435\n",
      "Epoch 178/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 58071.1385 - acc: 0.0000e+00 - val_loss: 21384.4490 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 163.86435\n",
      "Epoch 179/500\n",
      "538/538 [==============================] - 0s 275us/step - loss: 54486.8156 - acc: 0.0000e+00 - val_loss: 5313.9523 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 163.86435\n",
      "Epoch 180/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54780.4832 - acc: 0.0000e+00 - val_loss: 7492.6238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 163.86435\n",
      "Epoch 181/500\n",
      "538/538 [==============================] - 0s 185us/step - loss: 52972.0595 - acc: 0.0000e+00 - val_loss: 14814.7180 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 163.86435\n",
      "Epoch 182/500\n",
      "538/538 [==============================] - 0s 224us/step - loss: 52864.4872 - acc: 0.0000e+00 - val_loss: 8353.3995 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 163.86435\n",
      "Epoch 183/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 53772.1283 - acc: 0.0000e+00 - val_loss: 14664.2215 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 163.86435\n",
      "Epoch 184/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 54775.1104 - acc: 0.0000e+00 - val_loss: 8124.5162 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 163.86435\n",
      "Epoch 185/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 58676.3178 - acc: 0.0000e+00 - val_loss: 5861.4854 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 163.86435\n",
      "Epoch 186/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 56467.6262 - acc: 0.0000e+00 - val_loss: 318.3481 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 163.86435\n",
      "Epoch 187/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 53182.2030 - acc: 0.0000e+00 - val_loss: 12090.4609 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 163.86435\n",
      "Epoch 188/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 52389.2575 - acc: 0.0000e+00 - val_loss: 7814.6197 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 163.86435\n",
      "Epoch 189/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 55460.3810 - acc: 0.0000e+00 - val_loss: 15754.2539 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 163.86435\n",
      "Epoch 190/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 52477.6948 - acc: 0.0000e+00 - val_loss: 22433.9808 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 163.86435\n",
      "Epoch 191/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 55797.0493 - acc: 0.0000e+00 - val_loss: 5411.8241 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 163.86435\n",
      "Epoch 192/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 52672.5116 - acc: 0.0000e+00 - val_loss: 20681.6255 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 163.86435\n",
      "Epoch 193/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 55271.5532 - acc: 0.0000e+00 - val_loss: 5673.2352 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 163.86435\n",
      "Epoch 194/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 52398.8201 - acc: 0.0000e+00 - val_loss: 21383.0778 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 163.86435\n",
      "Epoch 195/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 53000.4834 - acc: 0.0000e+00 - val_loss: 11532.6887 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 163.86435\n",
      "Epoch 196/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 53742.0064 - acc: 0.0000e+00 - val_loss: 11732.3349 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 163.86435\n",
      "Epoch 197/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 55880.4492 - acc: 0.0000e+00 - val_loss: 1742.7998 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 163.86435\n",
      "Epoch 198/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 56511.2818 - acc: 0.0000e+00 - val_loss: 8578.9724 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 163.86435\n",
      "Epoch 199/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 54136.5915 - acc: 0.0000e+00 - val_loss: 1034.6002 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 163.86435\n",
      "Epoch 200/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 51615.7834 - acc: 0.0000e+00 - val_loss: 2994.8479 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 163.86435\n",
      "Epoch 201/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 53668.9084 - acc: 0.0000e+00 - val_loss: 2084.3380 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 163.86435\n",
      "Epoch 202/500\n",
      "538/538 [==============================] - 0s 186us/step - loss: 55050.5485 - acc: 0.0000e+00 - val_loss: 16098.1461 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 163.86435\n",
      "Epoch 203/500\n",
      "538/538 [==============================] - 0s 218us/step - loss: 57000.5071 - acc: 0.0000e+00 - val_loss: 1372.8197 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 163.86435\n",
      "Epoch 204/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 52970.2763 - acc: 0.0000e+00 - val_loss: 9025.9602 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 163.86435\n",
      "Epoch 205/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 54124.7653 - acc: 0.0000e+00 - val_loss: 6845.0155 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 163.86435\n",
      "Epoch 206/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 52927.1800 - acc: 0.0000e+00 - val_loss: 2124.3146 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 163.86435\n",
      "Epoch 207/500\n",
      "538/538 [==============================] - 0s 198us/step - loss: 55884.1292 - acc: 0.0000e+00 - val_loss: 33708.5315 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 163.86435\n",
      "Epoch 208/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 53421.2638 - acc: 0.0000e+00 - val_loss: 16457.8766 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 163.86435\n",
      "Epoch 209/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 55478.5373 - acc: 0.0000e+00 - val_loss: 9597.3565 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 163.86435\n",
      "Epoch 210/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 55104.8088 - acc: 0.0000e+00 - val_loss: 7507.3424 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 163.86435\n",
      "Epoch 211/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 55195.3479 - acc: 0.0000e+00 - val_loss: 517.5113 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 163.86435\n",
      "Epoch 212/500\n",
      "538/538 [==============================] - 0s 296us/step - loss: 55882.1499 - acc: 0.0000e+00 - val_loss: 13004.8783 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 163.86435\n",
      "Epoch 213/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 58040.7962 - acc: 0.0000e+00 - val_loss: 20718.5483 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 163.86435\n",
      "Epoch 214/500\n",
      "538/538 [==============================] - 0s 242us/step - loss: 56461.8927 - acc: 0.0000e+00 - val_loss: 15406.8676 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 163.86435\n",
      "Epoch 215/500\n",
      "538/538 [==============================] - 0s 258us/step - loss: 54443.7357 - acc: 0.0000e+00 - val_loss: 19082.9396 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 163.86435\n",
      "Epoch 216/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 54962.3724 - acc: 0.0000e+00 - val_loss: 3619.7655 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 163.86435\n",
      "Epoch 217/500\n",
      "538/538 [==============================] - 0s 281us/step - loss: 53998.6737 - acc: 0.0000e+00 - val_loss: 10584.6646 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 163.86435\n",
      "Epoch 218/500\n",
      "538/538 [==============================] - 0s 284us/step - loss: 51966.2443 - acc: 0.0000e+00 - val_loss: 4697.5359 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 163.86435\n",
      "Epoch 219/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 51384.0766 - acc: 0.0000e+00 - val_loss: 7947.5963 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 163.86435\n",
      "Epoch 220/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 58595.2706 - acc: 0.0000e+00 - val_loss: 3142.0123 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 163.86435\n",
      "Epoch 221/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 52535.9954 - acc: 0.0000e+00 - val_loss: 9287.4303 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 163.86435\n",
      "Epoch 222/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 56318.0820 - acc: 0.0000e+00 - val_loss: 15188.4782 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 163.86435\n",
      "Epoch 223/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 52716.6267 - acc: 0.0000e+00 - val_loss: 1829.5905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 163.86435\n",
      "Epoch 224/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 54470.3290 - acc: 0.0000e+00 - val_loss: 2297.3792 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 163.86435\n",
      "Epoch 225/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 53711.3708 - acc: 0.0000e+00 - val_loss: 2385.7111 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 163.86435\n",
      "Epoch 226/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 53126.9183 - acc: 0.0000e+00 - val_loss: 4018.2437 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 163.86435\n",
      "Epoch 227/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 53923.5439 - acc: 0.0000e+00 - val_loss: 15778.4011 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 163.86435\n",
      "Epoch 228/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 55300.3702 - acc: 0.0000e+00 - val_loss: 5384.7326 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 163.86435\n",
      "Epoch 229/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 53961.6785 - acc: 0.0000e+00 - val_loss: 9147.3657 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 163.86435\n",
      "Epoch 230/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 54105.6789 - acc: 0.0000e+00 - val_loss: 15167.6227 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 163.86435\n",
      "Epoch 231/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 58126.7639 - acc: 0.0000e+00 - val_loss: 32397.0769 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 163.86435\n",
      "Epoch 232/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 57256.9465 - acc: 0.0000e+00 - val_loss: 13102.4972 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 163.86435\n",
      "Epoch 233/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 57273.5992 - acc: 0.0000e+00 - val_loss: 21982.7449 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 163.86435\n",
      "Epoch 234/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 54899.3252 - acc: 0.0000e+00 - val_loss: 13748.6657 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 163.86435\n",
      "Epoch 235/500\n",
      "538/538 [==============================] - 0s 196us/step - loss: 54283.7516 - acc: 0.0000e+00 - val_loss: 2933.4817 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 163.86435\n",
      "Epoch 236/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 57609.8227 - acc: 0.0000e+00 - val_loss: 9136.3519 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 163.86435\n",
      "Epoch 237/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 57216.9632 - acc: 0.0000e+00 - val_loss: 9988.2928 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 163.86435\n",
      "Epoch 238/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 52660.8423 - acc: 0.0000e+00 - val_loss: 13904.1889 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 163.86435\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 208us/step - loss: 55808.1781 - acc: 0.0000e+00 - val_loss: 2488.2009 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 163.86435\n",
      "Epoch 240/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 53525.6328 - acc: 0.0000e+00 - val_loss: 14027.4963 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 163.86435\n",
      "Epoch 241/500\n",
      "538/538 [==============================] - 0s 187us/step - loss: 50625.8948 - acc: 0.0000e+00 - val_loss: 19580.4613 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 163.86435\n",
      "Epoch 242/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 56025.4106 - acc: 0.0000e+00 - val_loss: 21143.2188 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 163.86435\n",
      "Epoch 243/500\n",
      "538/538 [==============================] - 0s 262us/step - loss: 53263.1292 - acc: 0.0000e+00 - val_loss: 1335.4556 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 163.86435\n",
      "Epoch 244/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 54989.5395 - acc: 0.0000e+00 - val_loss: 12473.4477 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 163.86435\n",
      "Epoch 245/500\n",
      "538/538 [==============================] - 0s 260us/step - loss: 55841.3371 - acc: 0.0000e+00 - val_loss: 3207.9715 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 163.86435\n",
      "Epoch 246/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 54229.8241 - acc: 0.0000e+00 - val_loss: 31113.9053 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 163.86435\n",
      "Epoch 247/500\n",
      "538/538 [==============================] - 0s 299us/step - loss: 61148.1937 - acc: 0.0000e+00 - val_loss: 17918.6030 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 163.86435\n",
      "Epoch 248/500\n",
      "538/538 [==============================] - 0s 288us/step - loss: 58136.4405 - acc: 0.0000e+00 - val_loss: 9096.5532 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 163.86435\n",
      "Epoch 249/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 50614.8366 - acc: 0.0000e+00 - val_loss: 4882.5373 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 163.86435\n",
      "Epoch 250/500\n",
      "538/538 [==============================] - 0s 197us/step - loss: 53118.1386 - acc: 0.0000e+00 - val_loss: 7071.1199 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 163.86435\n",
      "Epoch 251/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 54084.1854 - acc: 0.0000e+00 - val_loss: 8034.3521 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 163.86435\n",
      "Epoch 252/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 54014.5578 - acc: 0.0000e+00 - val_loss: 5042.2701 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 163.86435\n",
      "Epoch 253/500\n",
      "538/538 [==============================] - 0s 200us/step - loss: 50646.4208 - acc: 0.0000e+00 - val_loss: 1557.5882 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 163.86435\n",
      "Epoch 254/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 53917.9227 - acc: 0.0000e+00 - val_loss: 1641.2593 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 163.86435\n",
      "Epoch 255/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 54086.0899 - acc: 0.0000e+00 - val_loss: 24328.0546 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 163.86435\n",
      "Epoch 256/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 56117.3006 - acc: 0.0000e+00 - val_loss: 3343.9437 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 163.86435\n",
      "Epoch 257/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 51659.2631 - acc: 0.0000e+00 - val_loss: 11272.5195 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 163.86435\n",
      "Epoch 258/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 52220.9718 - acc: 0.0000e+00 - val_loss: 22370.0639 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 163.86435\n",
      "Epoch 259/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 51574.9119 - acc: 0.0000e+00 - val_loss: 7751.0213 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 163.86435\n",
      "Epoch 260/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 55201.7132 - acc: 0.0000e+00 - val_loss: 6353.9500 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 163.86435\n",
      "Epoch 261/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 53802.4614 - acc: 0.0000e+00 - val_loss: 10563.4303 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 163.86435\n",
      "Epoch 262/500\n",
      "538/538 [==============================] - 0s 240us/step - loss: 56889.1338 - acc: 0.0000e+00 - val_loss: 12079.7627 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 163.86435\n",
      "Epoch 263/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 54158.7718 - acc: 0.0000e+00 - val_loss: 3023.4030 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 163.86435\n",
      "Epoch 264/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 51991.5630 - acc: 0.0000e+00 - val_loss: 4153.9220 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 163.86435\n",
      "Epoch 265/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 51851.9789 - acc: 0.0000e+00 - val_loss: 13148.5833 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 163.86435\n",
      "Epoch 266/500\n",
      "538/538 [==============================] - 0s 269us/step - loss: 56453.4786 - acc: 0.0000e+00 - val_loss: 10604.5829 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 163.86435\n",
      "Epoch 267/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 54621.3353 - acc: 0.0000e+00 - val_loss: 17349.6496 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 163.86435\n",
      "Epoch 268/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 56764.3360 - acc: 0.0000e+00 - val_loss: 6692.7477 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 163.86435\n",
      "Epoch 269/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 53309.6391 - acc: 0.0000e+00 - val_loss: 7378.8400 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 163.86435\n",
      "Epoch 270/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 53866.2921 - acc: 0.0000e+00 - val_loss: 15551.3639 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 163.86435\n",
      "Epoch 271/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 53945.4361 - acc: 0.0000e+00 - val_loss: 12370.4928 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 163.86435\n",
      "Epoch 272/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54048.8425 - acc: 0.0000e+00 - val_loss: 5836.5984 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 163.86435\n",
      "Epoch 273/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 54401.0507 - acc: 0.0000e+00 - val_loss: 5411.6255 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 163.86435\n",
      "Epoch 274/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 56072.7685 - acc: 0.0000e+00 - val_loss: 14272.5456 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 163.86435\n",
      "Epoch 275/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 54232.1982 - acc: 0.0000e+00 - val_loss: 2126.4157 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 163.86435\n",
      "Epoch 276/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 55094.4965 - acc: 0.0000e+00 - val_loss: 1676.8343 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 163.86435\n",
      "Epoch 277/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 55487.9087 - acc: 0.0000e+00 - val_loss: 17975.8458 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 163.86435\n",
      "Epoch 278/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 57342.2191 - acc: 0.0000e+00 - val_loss: 8568.6736 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 163.86435\n",
      "Epoch 279/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 204us/step - loss: 59931.1000 - acc: 0.0000e+00 - val_loss: 7526.8854 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 163.86435\n",
      "Epoch 280/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 56414.2159 - acc: 0.0000e+00 - val_loss: 10365.4664 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 163.86435\n",
      "Epoch 281/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 55630.1517 - acc: 0.0000e+00 - val_loss: 8562.8660 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 163.86435\n",
      "Epoch 282/500\n",
      "538/538 [==============================] - 0s 205us/step - loss: 57594.1184 - acc: 0.0000e+00 - val_loss: 5153.6680 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 163.86435\n",
      "Epoch 283/500\n",
      "538/538 [==============================] - 0s 205us/step - loss: 54501.5699 - acc: 0.0000e+00 - val_loss: 17971.5884 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 163.86435\n",
      "Epoch 284/500\n",
      "538/538 [==============================] - 0s 193us/step - loss: 52369.0699 - acc: 0.0000e+00 - val_loss: 45402.6879 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 163.86435\n",
      "Epoch 285/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 59531.1970 - acc: 0.0000e+00 - val_loss: 22355.6201 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 163.86435\n",
      "Epoch 286/500\n",
      "538/538 [==============================] - 0s 189us/step - loss: 58437.8612 - acc: 0.0000e+00 - val_loss: 4872.5067 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 163.86435\n",
      "Epoch 287/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 53769.9134 - acc: 0.0000e+00 - val_loss: 2144.9664 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 163.86435\n",
      "Epoch 288/500\n",
      "538/538 [==============================] - 0s 218us/step - loss: 52594.9204 - acc: 0.0000e+00 - val_loss: 3611.7398 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 163.86435\n",
      "Epoch 289/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 53322.2325 - acc: 0.0000e+00 - val_loss: 5709.7812 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 163.86435\n",
      "Epoch 290/500\n",
      "538/538 [==============================] - 0s 192us/step - loss: 53560.2405 - acc: 0.0000e+00 - val_loss: 8148.6039 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 163.86435\n",
      "Epoch 291/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 56438.9072 - acc: 0.0000e+00 - val_loss: 2663.4222 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 163.86435\n",
      "Epoch 292/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 57099.1985 - acc: 0.0000e+00 - val_loss: 5759.0944 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 163.86435\n",
      "Epoch 293/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 57989.8945 - acc: 0.0000e+00 - val_loss: 13925.8368 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 163.86435\n",
      "Epoch 294/500\n",
      "538/538 [==============================] - 0s 242us/step - loss: 54680.7734 - acc: 0.0000e+00 - val_loss: 16132.4838 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 163.86435\n",
      "Epoch 295/500\n",
      "538/538 [==============================] - 0s 262us/step - loss: 54363.0252 - acc: 0.0000e+00 - val_loss: 6554.6806 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 163.86435\n",
      "Epoch 296/500\n",
      "538/538 [==============================] - 0s 260us/step - loss: 56453.6457 - acc: 0.0000e+00 - val_loss: 2674.7537 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 163.86435\n",
      "Epoch 297/500\n",
      "538/538 [==============================] - 0s 277us/step - loss: 52949.9228 - acc: 0.0000e+00 - val_loss: 5719.2320 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 163.86435\n",
      "Epoch 298/500\n",
      "538/538 [==============================] - 0s 275us/step - loss: 56211.5802 - acc: 0.0000e+00 - val_loss: 21043.1713 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 163.86435\n",
      "Epoch 299/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 54248.1331 - acc: 0.0000e+00 - val_loss: 2621.6306 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 163.86435\n",
      "Epoch 300/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 51607.9576 - acc: 0.0000e+00 - val_loss: 21355.0041 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 163.86435\n",
      "Epoch 301/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 51712.8301 - acc: 0.0000e+00 - val_loss: 8799.7465 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 163.86435\n",
      "Epoch 302/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 55884.9080 - acc: 0.0000e+00 - val_loss: 14540.0845 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 163.86435\n",
      "Epoch 303/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 53323.4499 - acc: 0.0000e+00 - val_loss: 14864.4160 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 163.86435\n",
      "Epoch 304/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 53885.2429 - acc: 0.0000e+00 - val_loss: 1438.9595 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 163.86435\n",
      "Epoch 305/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 57662.9949 - acc: 0.0000e+00 - val_loss: 19646.8026 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 163.86435\n",
      "Epoch 306/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 54281.2521 - acc: 0.0000e+00 - val_loss: 8125.4491 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 163.86435\n",
      "Epoch 307/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 55865.9116 - acc: 0.0000e+00 - val_loss: 11853.0857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 163.86435\n",
      "Epoch 308/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 56315.4920 - acc: 0.0000e+00 - val_loss: 5058.5611 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 163.86435\n",
      "Epoch 309/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 56989.0678 - acc: 0.0000e+00 - val_loss: 7726.7512 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 163.86435\n",
      "Epoch 310/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 53881.1141 - acc: 0.0000e+00 - val_loss: 3231.3551 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 163.86435\n",
      "Epoch 311/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 50248.1332 - acc: 0.0000e+00 - val_loss: 3036.7829 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 163.86435\n",
      "Epoch 312/500\n",
      "538/538 [==============================] - 0s 211us/step - loss: 53705.4502 - acc: 0.0000e+00 - val_loss: 18113.8848 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 163.86435\n",
      "Epoch 313/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 52701.0689 - acc: 0.0000e+00 - val_loss: 1064.2627 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 163.86435\n",
      "Epoch 314/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 53566.7068 - acc: 0.0000e+00 - val_loss: 14437.4488 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 163.86435\n",
      "Epoch 315/500\n",
      "538/538 [==============================] - 0s 193us/step - loss: 53679.4268 - acc: 0.0000e+00 - val_loss: 1289.4789 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 163.86435\n",
      "Epoch 316/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 53712.4219 - acc: 0.0000e+00 - val_loss: 10881.4422 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 163.86435\n",
      "Epoch 317/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 52952.5998 - acc: 0.0000e+00 - val_loss: 7823.6870 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 163.86435\n",
      "Epoch 318/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 55343.7505 - acc: 0.0000e+00 - val_loss: 390.5225 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 163.86435\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 206us/step - loss: 52905.3659 - acc: 0.0000e+00 - val_loss: 9544.0718 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 163.86435\n",
      "Epoch 320/500\n",
      "538/538 [==============================] - 0s 226us/step - loss: 54925.2688 - acc: 0.0000e+00 - val_loss: 3438.3512 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 163.86435\n",
      "Epoch 321/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 54805.1483 - acc: 0.0000e+00 - val_loss: 18761.4817 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 163.86435\n",
      "Epoch 322/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 53105.9471 - acc: 0.0000e+00 - val_loss: 14316.3634 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 163.86435\n",
      "Epoch 323/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 53514.4103 - acc: 0.0000e+00 - val_loss: 10541.3363 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 163.86435\n",
      "Epoch 324/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 54312.2712 - acc: 0.0000e+00 - val_loss: 27663.2273 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 163.86435\n",
      "Epoch 325/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 55950.0037 - acc: 0.0000e+00 - val_loss: 19302.5683 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 163.86435\n",
      "Epoch 326/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 55112.0978 - acc: 0.0000e+00 - val_loss: 10358.5530 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 163.86435\n",
      "Epoch 327/500\n",
      "538/538 [==============================] - 0s 209us/step - loss: 61111.7201 - acc: 0.0000e+00 - val_loss: 23834.1593 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 163.86435\n",
      "Epoch 328/500\n",
      "538/538 [==============================] - 0s 186us/step - loss: 54224.6031 - acc: 0.0000e+00 - val_loss: 6552.4310 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 163.86435\n",
      "Epoch 329/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 49607.6132 - acc: 0.0000e+00 - val_loss: 4916.2056 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 163.86435\n",
      "Epoch 330/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 54350.8963 - acc: 0.0000e+00 - val_loss: 5078.2215 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 163.86435\n",
      "Epoch 331/500\n",
      "538/538 [==============================] - 0s 185us/step - loss: 56952.8672 - acc: 0.0000e+00 - val_loss: 20435.1185 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 163.86435\n",
      "Epoch 332/500\n",
      "538/538 [==============================] - 0s 218us/step - loss: 61747.8495 - acc: 0.0000e+00 - val_loss: 24343.8983 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 163.86435\n",
      "Epoch 333/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 53308.2205 - acc: 0.0000e+00 - val_loss: 4485.0451 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 163.86435\n",
      "Epoch 334/500\n",
      "538/538 [==============================] - 0s 205us/step - loss: 55445.8882 - acc: 0.0000e+00 - val_loss: 7516.7053 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 163.86435\n",
      "Epoch 335/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 55989.6368 - acc: 0.0000e+00 - val_loss: 4569.5171 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 163.86435\n",
      "Epoch 336/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 53643.8532 - acc: 0.0000e+00 - val_loss: 19213.6329 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 163.86435\n",
      "Epoch 337/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 54771.3991 - acc: 0.0000e+00 - val_loss: 4089.4599 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 163.86435\n",
      "Epoch 338/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 55278.4588 - acc: 0.0000e+00 - val_loss: 3261.1984 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 163.86435\n",
      "Epoch 339/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 55141.0200 - acc: 0.0000e+00 - val_loss: 15217.1859 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 163.86435\n",
      "Epoch 340/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 53772.5332 - acc: 0.0000e+00 - val_loss: 4660.8058 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 163.86435\n",
      "Epoch 341/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 54272.1773 - acc: 0.0000e+00 - val_loss: 9917.3537 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 163.86435\n",
      "Epoch 342/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54174.4125 - acc: 0.0000e+00 - val_loss: 8528.3660 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 163.86435\n",
      "Epoch 343/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 58289.7603 - acc: 0.0000e+00 - val_loss: 12088.8961 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 163.86435\n",
      "Epoch 344/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 55840.4941 - acc: 0.0000e+00 - val_loss: 9581.0599 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 163.86435\n",
      "Epoch 345/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 54612.9549 - acc: 0.0000e+00 - val_loss: 18918.8607 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 163.86435\n",
      "Epoch 346/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 58433.6824 - acc: 0.0000e+00 - val_loss: 22059.5560 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 163.86435\n",
      "Epoch 347/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 52397.7003 - acc: 0.0000e+00 - val_loss: 7282.9352 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 163.86435\n",
      "Epoch 348/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 53596.8346 - acc: 0.0000e+00 - val_loss: 1079.1486 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 163.86435\n",
      "Epoch 349/500\n",
      "538/538 [==============================] - 0s 221us/step - loss: 52494.1606 - acc: 0.0000e+00 - val_loss: 32299.1613 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 163.86435\n",
      "Epoch 350/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 56330.5471 - acc: 0.0000e+00 - val_loss: 671.8132 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 163.86435\n",
      "Epoch 351/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 56863.6228 - acc: 0.0000e+00 - val_loss: 25246.0569 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 163.86435\n",
      "Epoch 352/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 59597.1354 - acc: 0.0000e+00 - val_loss: 5054.4713 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 163.86435\n",
      "Epoch 353/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 58404.2088 - acc: 0.0000e+00 - val_loss: 21948.9042 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 163.86435\n",
      "Epoch 354/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 57419.9310 - acc: 0.0000e+00 - val_loss: 8346.5123 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 163.86435\n",
      "Epoch 355/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 53243.6704 - acc: 0.0000e+00 - val_loss: 941.1843 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 163.86435\n",
      "Epoch 356/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 54932.9196 - acc: 0.0000e+00 - val_loss: 631.0574 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 163.86435\n",
      "Epoch 357/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 57024.9539 - acc: 0.0000e+00 - val_loss: 20096.8308 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 163.86435\n",
      "Epoch 358/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 61088.2430 - acc: 0.0000e+00 - val_loss: 11480.9229 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 163.86435\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 223us/step - loss: 55961.1051 - acc: 0.0019 - val_loss: 11639.5965 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 163.86435\n",
      "Epoch 360/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 54720.9223 - acc: 0.0000e+00 - val_loss: 1850.0921 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 163.86435\n",
      "Epoch 361/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 51681.2217 - acc: 0.0000e+00 - val_loss: 6705.8856 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 163.86435\n",
      "Epoch 362/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 53444.1964 - acc: 0.0000e+00 - val_loss: 4664.9569 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 163.86435\n",
      "Epoch 363/500\n",
      "538/538 [==============================] - 0s 191us/step - loss: 52502.3959 - acc: 0.0000e+00 - val_loss: 17469.6247 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 163.86435\n",
      "Epoch 364/500\n",
      "538/538 [==============================] - 0s 199us/step - loss: 51988.0154 - acc: 0.0000e+00 - val_loss: 4591.6491 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 163.86435\n",
      "Epoch 365/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 53692.3687 - acc: 0.0000e+00 - val_loss: 19049.8296 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 163.86435\n",
      "Epoch 366/500\n",
      "538/538 [==============================] - 0s 310us/step - loss: 51821.6032 - acc: 0.0000e+00 - val_loss: 11065.9768 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 163.86435\n",
      "Epoch 367/500\n",
      "538/538 [==============================] - 0s 307us/step - loss: 53999.8338 - acc: 0.0000e+00 - val_loss: 11763.3345 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 163.86435\n",
      "Epoch 368/500\n",
      "538/538 [==============================] - 0s 307us/step - loss: 54169.7830 - acc: 0.0000e+00 - val_loss: 12792.9459 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 163.86435\n",
      "Epoch 369/500\n",
      "538/538 [==============================] - 0s 268us/step - loss: 60213.6478 - acc: 0.0000e+00 - val_loss: 2616.6806 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 163.86435\n",
      "Epoch 370/500\n",
      "538/538 [==============================] - 0s 286us/step - loss: 54396.9516 - acc: 0.0000e+00 - val_loss: 8559.0130 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 163.86435\n",
      "Epoch 371/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 51953.1713 - acc: 0.0000e+00 - val_loss: 1730.7794 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 163.86435\n",
      "Epoch 372/500\n",
      "538/538 [==============================] - 0s 247us/step - loss: 55132.5935 - acc: 0.0000e+00 - val_loss: 3186.8903 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 163.86435\n",
      "Epoch 373/500\n",
      "538/538 [==============================] - 0s 275us/step - loss: 54496.1131 - acc: 0.0000e+00 - val_loss: 15599.4836 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 163.86435\n",
      "Epoch 374/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 54538.4739 - acc: 0.0000e+00 - val_loss: 2247.7046 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 163.86435\n",
      "Epoch 375/500\n",
      "538/538 [==============================] - 0s 276us/step - loss: 53966.9893 - acc: 0.0000e+00 - val_loss: 8727.0880 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 163.86435\n",
      "Epoch 376/500\n",
      "538/538 [==============================] - 0s 288us/step - loss: 55590.1097 - acc: 0.0000e+00 - val_loss: 7326.1838 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 163.86435\n",
      "Epoch 377/500\n",
      "538/538 [==============================] - 0s 292us/step - loss: 56478.4560 - acc: 0.0000e+00 - val_loss: 9223.3194 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 163.86435\n",
      "Epoch 378/500\n",
      "538/538 [==============================] - 0s 279us/step - loss: 53582.1336 - acc: 0.0000e+00 - val_loss: 25612.1634 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 163.86435\n",
      "Epoch 379/500\n",
      "538/538 [==============================] - 0s 255us/step - loss: 58070.8580 - acc: 0.0000e+00 - val_loss: 2409.3282 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 163.86435\n",
      "Epoch 380/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 54798.7316 - acc: 0.0000e+00 - val_loss: 5156.4081 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 163.86435\n",
      "Epoch 381/500\n",
      "538/538 [==============================] - 0s 247us/step - loss: 56314.6089 - acc: 0.0000e+00 - val_loss: 7270.6403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 163.86435\n",
      "Epoch 382/500\n",
      "538/538 [==============================] - 0s 255us/step - loss: 54440.3117 - acc: 0.0000e+00 - val_loss: 22206.6182 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 163.86435\n",
      "Epoch 383/500\n",
      "538/538 [==============================] - 0s 251us/step - loss: 53703.2757 - acc: 0.0000e+00 - val_loss: 14471.7394 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 163.86435\n",
      "Epoch 384/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 55155.4543 - acc: 0.0000e+00 - val_loss: 9354.4280 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 163.86435\n",
      "Epoch 385/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 62899.4220 - acc: 0.0000e+00 - val_loss: 9582.5058 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 163.86435\n",
      "Epoch 386/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 51768.2477 - acc: 0.0000e+00 - val_loss: 20813.5504 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 163.86435\n",
      "Epoch 387/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 51473.0707 - acc: 0.0000e+00 - val_loss: 22256.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 163.86435\n",
      "Epoch 388/500\n",
      "538/538 [==============================] - 0s 262us/step - loss: 54675.3924 - acc: 0.0000e+00 - val_loss: 4572.3326 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 163.86435\n",
      "Epoch 389/500\n",
      "538/538 [==============================] - 0s 269us/step - loss: 53721.7794 - acc: 0.0000e+00 - val_loss: 18953.7439 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 163.86435\n",
      "Epoch 390/500\n",
      "538/538 [==============================] - 0s 284us/step - loss: 55517.8891 - acc: 0.0000e+00 - val_loss: 3865.0736 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 163.86435\n",
      "Epoch 391/500\n",
      "538/538 [==============================] - 0s 243us/step - loss: 54742.1949 - acc: 0.0000e+00 - val_loss: 6687.1076 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 163.86435\n",
      "Epoch 392/500\n",
      "538/538 [==============================] - 0s 253us/step - loss: 53545.9577 - acc: 0.0000e+00 - val_loss: 14728.8276 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 163.86435\n",
      "Epoch 393/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 53730.8267 - acc: 0.0000e+00 - val_loss: 2399.9076 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 163.86435\n",
      "Epoch 394/500\n",
      "538/538 [==============================] - 0s 288us/step - loss: 57146.5902 - acc: 0.0000e+00 - val_loss: 9870.6041 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 163.86435\n",
      "Epoch 395/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 52207.4329 - acc: 0.0000e+00 - val_loss: 9627.8415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 163.86435\n",
      "Epoch 396/500\n",
      "538/538 [==============================] - 0s 197us/step - loss: 51790.5921 - acc: 0.0000e+00 - val_loss: 6369.1266 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 163.86435\n",
      "Epoch 397/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 54393.9772 - acc: 0.0000e+00 - val_loss: 5282.9637 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 163.86435\n",
      "Epoch 398/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 54568.1266 - acc: 0.0000e+00 - val_loss: 13492.5350 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 163.86435\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 202us/step - loss: 54215.1461 - acc: 0.0000e+00 - val_loss: 3757.2343 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 163.86435\n",
      "Epoch 400/500\n",
      "538/538 [==============================] - 0s 236us/step - loss: 55196.9977 - acc: 0.0000e+00 - val_loss: 976.2852 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 163.86435\n",
      "Epoch 401/500\n",
      "538/538 [==============================] - 0s 196us/step - loss: 50024.8094 - acc: 0.0000e+00 - val_loss: 16270.4329 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 163.86435\n",
      "Epoch 402/500\n",
      "538/538 [==============================] - 0s 216us/step - loss: 57595.7736 - acc: 0.0000e+00 - val_loss: 703.3475 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 163.86435\n",
      "Epoch 403/500\n",
      "538/538 [==============================] - 0s 198us/step - loss: 54537.4727 - acc: 0.0000e+00 - val_loss: 22520.0405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 163.86435\n",
      "Epoch 404/500\n",
      "538/538 [==============================] - 0s 209us/step - loss: 55530.0342 - acc: 0.0000e+00 - val_loss: 3304.3231 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 163.86435\n",
      "Epoch 405/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 53473.8162 - acc: 0.0000e+00 - val_loss: 15289.9201 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 163.86435\n",
      "Epoch 406/500\n",
      "538/538 [==============================] - 0s 269us/step - loss: 59465.4659 - acc: 0.0000e+00 - val_loss: 32004.3931 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 163.86435\n",
      "Epoch 407/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 56141.9441 - acc: 0.0000e+00 - val_loss: 9271.2164 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 163.86435\n",
      "Epoch 408/500\n",
      "538/538 [==============================] - 0s 247us/step - loss: 56046.5297 - acc: 0.0000e+00 - val_loss: 10540.9836 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 163.86435\n",
      "Epoch 409/500\n",
      "538/538 [==============================] - 0s 209us/step - loss: 50761.7396 - acc: 0.0000e+00 - val_loss: 4697.6991 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 163.86435\n",
      "Epoch 410/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 53348.3799 - acc: 0.0000e+00 - val_loss: 5344.6324 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 163.86435\n",
      "Epoch 411/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 51580.3595 - acc: 0.0000e+00 - val_loss: 1898.2961 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 163.86435\n",
      "Epoch 412/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 54164.4418 - acc: 0.0000e+00 - val_loss: 3771.8042 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 163.86435\n",
      "Epoch 413/500\n",
      "538/538 [==============================] - 0s 249us/step - loss: 54777.2100 - acc: 0.0000e+00 - val_loss: 7684.6268 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 163.86435\n",
      "Epoch 414/500\n",
      "538/538 [==============================] - 0s 268us/step - loss: 54748.6405 - acc: 0.0000e+00 - val_loss: 6942.8405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 163.86435\n",
      "Epoch 415/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 51359.0645 - acc: 0.0000e+00 - val_loss: 8404.8991 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 163.86435\n",
      "Epoch 416/500\n",
      "538/538 [==============================] - 0s 211us/step - loss: 54048.8166 - acc: 0.0000e+00 - val_loss: 3849.0150 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 163.86435\n",
      "Epoch 417/500\n",
      "538/538 [==============================] - 0s 189us/step - loss: 54725.4914 - acc: 0.0000e+00 - val_loss: 7327.4005 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 163.86435\n",
      "Epoch 418/500\n",
      "538/538 [==============================] - 0s 231us/step - loss: 53561.6052 - acc: 0.0000e+00 - val_loss: 8447.0597 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 163.86435\n",
      "Epoch 419/500\n",
      "538/538 [==============================] - 0s 206us/step - loss: 52368.5166 - acc: 0.0000e+00 - val_loss: 2350.5877 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 163.86435\n",
      "Epoch 420/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 57747.6145 - acc: 0.0000e+00 - val_loss: 46979.1218 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 163.86435\n",
      "Epoch 421/500\n",
      "538/538 [==============================] - 0s 228us/step - loss: 59709.6483 - acc: 0.0000e+00 - val_loss: 2775.0801 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 163.86435\n",
      "Epoch 422/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 51963.7646 - acc: 0.0000e+00 - val_loss: 11360.7502 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 163.86435\n",
      "Epoch 423/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 54199.5827 - acc: 0.0000e+00 - val_loss: 22962.2292 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 163.86435\n",
      "Epoch 424/500\n",
      "538/538 [==============================] - 0s 217us/step - loss: 53841.3141 - acc: 0.0000e+00 - val_loss: 3154.5905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 163.86435\n",
      "Epoch 425/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54686.2756 - acc: 0.0000e+00 - val_loss: 14129.2984 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 163.86435\n",
      "Epoch 426/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 58871.9579 - acc: 0.0000e+00 - val_loss: 23810.7921 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 163.86435\n",
      "Epoch 427/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 54384.3644 - acc: 0.0000e+00 - val_loss: 3411.0532 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 163.86435\n",
      "Epoch 428/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 52507.2005 - acc: 0.0000e+00 - val_loss: 9445.6690 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 163.86435\n",
      "Epoch 429/500\n",
      "538/538 [==============================] - 0s 197us/step - loss: 53267.5595 - acc: 0.0000e+00 - val_loss: 16728.5125 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 163.86435\n",
      "Epoch 430/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54020.9377 - acc: 0.0000e+00 - val_loss: 4973.9706 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 163.86435\n",
      "Epoch 431/500\n",
      "538/538 [==============================] - 0s 212us/step - loss: 51512.3685 - acc: 0.0000e+00 - val_loss: 2671.9220 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 163.86435\n",
      "Epoch 432/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 54836.7075 - acc: 0.0000e+00 - val_loss: 5044.7961 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 163.86435\n",
      "Epoch 433/500\n",
      "538/538 [==============================] - 0s 210us/step - loss: 57478.4152 - acc: 0.0000e+00 - val_loss: 9397.2704 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 163.86435\n",
      "Epoch 434/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 53874.1786 - acc: 0.0000e+00 - val_loss: 25819.8260 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 163.86435\n",
      "Epoch 435/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 56769.6867 - acc: 0.0000e+00 - val_loss: 1477.3546 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 163.86435\n",
      "Epoch 436/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 50798.5202 - acc: 0.0000e+00 - val_loss: 8354.3854 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 163.86435\n",
      "Epoch 437/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 55117.8120 - acc: 0.0000e+00 - val_loss: 20678.5625 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 163.86435\n",
      "Epoch 438/500\n",
      "538/538 [==============================] - 0s 197us/step - loss: 55237.1225 - acc: 0.0000e+00 - val_loss: 4538.2137 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 163.86435\n",
      "Epoch 439/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 201us/step - loss: 57603.7255 - acc: 0.0000e+00 - val_loss: 9994.1423 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 163.86435\n",
      "Epoch 440/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 56940.6524 - acc: 0.0000e+00 - val_loss: 8154.5125 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 163.86435\n",
      "Epoch 441/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 53621.6511 - acc: 0.0000e+00 - val_loss: 9415.4574 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 163.86435\n",
      "Epoch 442/500\n",
      "538/538 [==============================] - 0s 192us/step - loss: 55183.0070 - acc: 0.0000e+00 - val_loss: 4604.8690 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 163.86435\n",
      "Epoch 443/500\n",
      "538/538 [==============================] - 0s 187us/step - loss: 52457.2728 - acc: 0.0000e+00 - val_loss: 4157.7856 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 163.86435\n",
      "Epoch 444/500\n",
      "538/538 [==============================] - 0s 266us/step - loss: 53187.8691 - acc: 0.0000e+00 - val_loss: 11316.2921 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 163.86435\n",
      "Epoch 445/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 52404.7649 - acc: 0.0000e+00 - val_loss: 2177.8285 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 163.86435\n",
      "Epoch 446/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 52502.1487 - acc: 0.0000e+00 - val_loss: 14851.3933 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 163.86435\n",
      "Epoch 447/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 63678.6698 - acc: 0.0000e+00 - val_loss: 32168.8977 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 163.86435\n",
      "Epoch 448/500\n",
      "538/538 [==============================] - 0s 203us/step - loss: 57572.0897 - acc: 0.0000e+00 - val_loss: 1432.9725 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 163.86435\n",
      "Epoch 449/500\n",
      "538/538 [==============================] - 0s 213us/step - loss: 53984.5110 - acc: 0.0000e+00 - val_loss: 12278.9211 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 163.86435\n",
      "Epoch 450/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 57092.9384 - acc: 0.0000e+00 - val_loss: 10730.7586 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 163.86435\n",
      "Epoch 451/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 50331.3530 - acc: 0.0000e+00 - val_loss: 6668.0370 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 163.86435\n",
      "Epoch 452/500\n",
      "538/538 [==============================] - 0s 214us/step - loss: 56246.4482 - acc: 0.0000e+00 - val_loss: 623.6859 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 163.86435\n",
      "Epoch 453/500\n",
      "538/538 [==============================] - 0s 205us/step - loss: 52637.4991 - acc: 0.0000e+00 - val_loss: 8374.9655 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 163.86435\n",
      "Epoch 454/500\n",
      "538/538 [==============================] - 0s 220us/step - loss: 55840.9774 - acc: 0.0000e+00 - val_loss: 3720.5488 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 163.86435\n",
      "Epoch 455/500\n",
      "538/538 [==============================] - 0s 208us/step - loss: 60051.8887 - acc: 0.0000e+00 - val_loss: 24740.8196 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 163.86435\n",
      "Epoch 456/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 53086.8509 - acc: 0.0000e+00 - val_loss: 9129.7454 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 163.86435\n",
      "Epoch 457/500\n",
      "538/538 [==============================] - 0s 241us/step - loss: 57378.5060 - acc: 0.0000e+00 - val_loss: 13007.6183 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 163.86435\n",
      "Epoch 458/500\n",
      "538/538 [==============================] - 0s 230us/step - loss: 53426.0663 - acc: 0.0000e+00 - val_loss: 3741.3310 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 163.86435\n",
      "Epoch 459/500\n",
      "538/538 [==============================] - 0s 256us/step - loss: 51919.6252 - acc: 0.0000e+00 - val_loss: 4502.9833 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 163.86435\n",
      "Epoch 460/500\n",
      "538/538 [==============================] - 0s 273us/step - loss: 53002.6397 - acc: 0.0000e+00 - val_loss: 4674.9475 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 163.86435\n",
      "Epoch 461/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 53620.0892 - acc: 0.0000e+00 - val_loss: 7747.5403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 163.86435\n",
      "Epoch 462/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 56154.6017 - acc: 0.0000e+00 - val_loss: 6156.8350 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 163.86435\n",
      "Epoch 463/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 54483.1281 - acc: 0.0000e+00 - val_loss: 16441.1421 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 163.86435\n",
      "Epoch 464/500\n",
      "538/538 [==============================] - 0s 223us/step - loss: 57801.1121 - acc: 0.0000e+00 - val_loss: 6382.6051 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 163.86435\n",
      "Epoch 465/500\n",
      "538/538 [==============================] - 0s 245us/step - loss: 53580.5391 - acc: 0.0000e+00 - val_loss: 24296.7067 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 163.86435\n",
      "Epoch 466/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 56295.0051 - acc: 0.0000e+00 - val_loss: 6947.5382 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 163.86435\n",
      "Epoch 467/500\n",
      "538/538 [==============================] - 0s 229us/step - loss: 54430.8733 - acc: 0.0000e+00 - val_loss: 12593.1190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 163.86435\n",
      "Epoch 468/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 56120.2439 - acc: 0.0000e+00 - val_loss: 2544.3322 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 163.86435\n",
      "Epoch 469/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 56835.8007 - acc: 0.0000e+00 - val_loss: 2869.6671 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 163.86435\n",
      "Epoch 470/500\n",
      "538/538 [==============================] - 0s 227us/step - loss: 57600.0740 - acc: 0.0000e+00 - val_loss: 22813.4426 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 163.86435\n",
      "Epoch 471/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 54789.9027 - acc: 0.0000e+00 - val_loss: 741.4407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 163.86435\n",
      "Epoch 472/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 54324.3752 - acc: 0.0000e+00 - val_loss: 6822.9850 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 163.86435\n",
      "Epoch 473/500\n",
      "538/538 [==============================] - 0s 215us/step - loss: 57041.8759 - acc: 0.0000e+00 - val_loss: 24357.6428 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 163.86435\n",
      "Epoch 474/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 54312.9215 - acc: 0.0000e+00 - val_loss: 19227.7607 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 163.86435\n",
      "Epoch 475/500\n",
      "538/538 [==============================] - 0s 204us/step - loss: 57207.4480 - acc: 0.0000e+00 - val_loss: 4797.8942 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 163.86435\n",
      "Epoch 476/500\n",
      "538/538 [==============================] - 0s 195us/step - loss: 54957.2685 - acc: 0.0000e+00 - val_loss: 1452.6125 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 163.86435\n",
      "Epoch 477/500\n",
      "538/538 [==============================] - 0s 234us/step - loss: 57189.3050 - acc: 0.0000e+00 - val_loss: 2313.0396 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 163.86435\n",
      "Epoch 478/500\n",
      "538/538 [==============================] - 0s 225us/step - loss: 52669.3671 - acc: 0.0000e+00 - val_loss: 12234.5526 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 163.86435\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 234us/step - loss: 58195.3638 - acc: 0.0000e+00 - val_loss: 700.4634 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 163.86435\n",
      "Epoch 480/500\n",
      "538/538 [==============================] - 0s 299us/step - loss: 53852.7221 - acc: 0.0000e+00 - val_loss: 14164.9845 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 163.86435\n",
      "Epoch 481/500\n",
      "538/538 [==============================] - 0s 342us/step - loss: 54593.1842 - acc: 0.0000e+00 - val_loss: 7263.0505 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 163.86435\n",
      "Epoch 482/500\n",
      "538/538 [==============================] - 0s 320us/step - loss: 53525.7704 - acc: 0.0000e+00 - val_loss: 1265.0593 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 163.86435\n",
      "Epoch 483/500\n",
      "538/538 [==============================] - 0s 349us/step - loss: 54735.9407 - acc: 0.0000e+00 - val_loss: 12750.2331 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 163.86435\n",
      "Epoch 484/500\n",
      "538/538 [==============================] - 0s 329us/step - loss: 53736.5168 - acc: 0.0000e+00 - val_loss: 12034.3588 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 163.86435\n",
      "Epoch 485/500\n",
      "538/538 [==============================] - 0s 318us/step - loss: 55331.7866 - acc: 0.0000e+00 - val_loss: 6767.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 163.86435\n",
      "Epoch 486/500\n",
      "538/538 [==============================] - 0s 333us/step - loss: 54969.0576 - acc: 0.0000e+00 - val_loss: 3485.1199 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 163.86435\n",
      "Epoch 487/500\n",
      "538/538 [==============================] - 0s 310us/step - loss: 54639.9487 - acc: 0.0000e+00 - val_loss: 10354.4472 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 163.86435\n",
      "Epoch 488/500\n",
      "538/538 [==============================] - 0s 312us/step - loss: 57490.1032 - acc: 0.0000e+00 - val_loss: 13043.7187 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 163.86435\n",
      "Epoch 489/500\n",
      "538/538 [==============================] - 0s 307us/step - loss: 55518.2900 - acc: 0.0000e+00 - val_loss: 23041.8979 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 163.86435\n",
      "Epoch 490/500\n",
      "538/538 [==============================] - 0s 333us/step - loss: 54754.1754 - acc: 0.0000e+00 - val_loss: 379.0368 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 163.86435\n",
      "Epoch 491/500\n",
      "538/538 [==============================] - 0s 295us/step - loss: 55432.1205 - acc: 0.0000e+00 - val_loss: 28340.0678 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 163.86435\n",
      "Epoch 492/500\n",
      "538/538 [==============================] - 0s 331us/step - loss: 56087.6633 - acc: 0.0000e+00 - val_loss: 8617.0296 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 163.86435\n",
      "Epoch 493/500\n",
      "538/538 [==============================] - 0s 305us/step - loss: 51116.7857 - acc: 0.0000e+00 - val_loss: 9066.5900 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 163.86435\n",
      "Epoch 494/500\n",
      "538/538 [==============================] - 0s 290us/step - loss: 53000.2937 - acc: 0.0000e+00 - val_loss: 14202.6975 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 163.86435\n",
      "Epoch 495/500\n",
      "538/538 [==============================] - 0s 219us/step - loss: 55182.0583 - acc: 0.0000e+00 - val_loss: 6766.2676 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 163.86435\n",
      "Epoch 496/500\n",
      "538/538 [==============================] - 0s 286us/step - loss: 54156.8761 - acc: 0.0000e+00 - val_loss: 330.7634 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 163.86435\n",
      "Epoch 497/500\n",
      "538/538 [==============================] - 0s 238us/step - loss: 54433.3966 - acc: 0.0000e+00 - val_loss: 15818.4528 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 163.86435\n",
      "Epoch 498/500\n",
      "538/538 [==============================] - 0s 201us/step - loss: 55816.8521 - acc: 0.0000e+00 - val_loss: 1842.6211 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 163.86435\n",
      "Epoch 499/500\n",
      "538/538 [==============================] - 0s 190us/step - loss: 53632.1445 - acc: 0.0000e+00 - val_loss: 15574.4002 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 163.86435\n",
      "Epoch 500/500\n",
      "538/538 [==============================] - 0s 202us/step - loss: 57500.5277 - acc: 0.0000e+00 - val_loss: 1001.1067 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 163.86435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2574162e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(X, y, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'Weights.best.hdf5'\n",
    "NN_model.load_weights(weights_file)\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 0s 492us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1449.061060549777, 1449.061060549777]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = NN_model.evaluate(X, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_absolute_error']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[757204.9 ],\n",
       "       [756732.9 ],\n",
       "       [756261.  ],\n",
       "       [755788.94],\n",
       "       [755317.06],\n",
       "       [754845.06],\n",
       "       [754373.1 ],\n",
       "       [753901.2 ],\n",
       "       [753429.25],\n",
       "       [752957.3 ],\n",
       "       [752485.4 ],\n",
       "       [752013.5 ],\n",
       "       [751541.5 ],\n",
       "       [751069.56],\n",
       "       [750597.56],\n",
       "       [750125.6 ],\n",
       "       [749653.75],\n",
       "       [749181.75],\n",
       "       [748709.9 ],\n",
       "       [748237.9 ],\n",
       "       [747765.94],\n",
       "       [747294.06],\n",
       "       [746822.  ],\n",
       "       [746350.06],\n",
       "       [745878.1 ],\n",
       "       [745406.2 ],\n",
       "       [744934.25],\n",
       "       [744462.3 ],\n",
       "       [743990.3 ],\n",
       "       [743518.4 ],\n",
       "       [743046.5 ],\n",
       "       [742574.56],\n",
       "       [742102.6 ],\n",
       "       [741630.6 ],\n",
       "       [741158.6 ],\n",
       "       [740686.75],\n",
       "       [740214.75],\n",
       "       [739742.9 ],\n",
       "       [739270.9 ],\n",
       "       [738799.  ],\n",
       "       [738327.  ],\n",
       "       [737855.  ],\n",
       "       [737383.1 ],\n",
       "       [736911.2 ],\n",
       "       [736439.1 ],\n",
       "       [735967.25],\n",
       "       [735495.4 ],\n",
       "       [735023.3 ],\n",
       "       [734551.4 ],\n",
       "       [734079.5 ],\n",
       "       [733607.56],\n",
       "       [733135.5 ],\n",
       "       [732663.6 ],\n",
       "       [732191.6 ],\n",
       "       [731719.7 ],\n",
       "       [731247.8 ],\n",
       "       [730775.9 ],\n",
       "       [730303.8 ],\n",
       "       [729831.94],\n",
       "       [729360.  ],\n",
       "       [728888.06],\n",
       "       [728416.06],\n",
       "       [727944.06],\n",
       "       [727472.1 ],\n",
       "       [727000.25],\n",
       "       [726528.2 ],\n",
       "       [726056.4 ],\n",
       "       [725584.4 ],\n",
       "       [725112.4 ],\n",
       "       [724640.44],\n",
       "       [724168.5 ],\n",
       "       [723696.56],\n",
       "       [723224.6 ],\n",
       "       [722752.6 ],\n",
       "       [722280.6 ],\n",
       "       [721808.75],\n",
       "       [721336.75],\n",
       "       [720864.75],\n",
       "       [720392.9 ],\n",
       "       [719920.9 ],\n",
       "       [719449.  ],\n",
       "       [718976.94],\n",
       "       [718505.  ],\n",
       "       [718033.06],\n",
       "       [717561.1 ],\n",
       "       [717089.2 ],\n",
       "       [716617.25],\n",
       "       [716145.25],\n",
       "       [715673.4 ],\n",
       "       [715201.4 ],\n",
       "       [714729.4 ],\n",
       "       [714257.44],\n",
       "       [713785.5 ],\n",
       "       [713313.56],\n",
       "       [712841.6 ],\n",
       "       [712369.6 ],\n",
       "       [711897.56],\n",
       "       [711425.75],\n",
       "       [710953.75],\n",
       "       [710481.75],\n",
       "       [710009.8 ],\n",
       "       [709537.8 ],\n",
       "       [709065.94],\n",
       "       [708594.  ],\n",
       "       [708122.  ],\n",
       "       [707650.06],\n",
       "       [707178.1 ],\n",
       "       [706706.1 ],\n",
       "       [706234.2 ],\n",
       "       [705762.25],\n",
       "       [705290.25],\n",
       "       [704818.25],\n",
       "       [704346.4 ],\n",
       "       [703874.4 ],\n",
       "       [703402.44],\n",
       "       [702930.44],\n",
       "       [702458.56],\n",
       "       [701986.56],\n",
       "       [701514.6 ],\n",
       "       [701042.6 ],\n",
       "       [700570.75],\n",
       "       [700098.7 ],\n",
       "       [699626.75],\n",
       "       [699154.8 ],\n",
       "       [698682.9 ],\n",
       "       [698210.9 ],\n",
       "       [697738.94],\n",
       "       [697266.9 ],\n",
       "       [696795.  ],\n",
       "       [696323.06],\n",
       "       [695851.1 ],\n",
       "       [695379.1 ],\n",
       "       [694907.2 ],\n",
       "       [694435.25],\n",
       "       [693963.25],\n",
       "       [693491.3 ],\n",
       "       [693019.4 ],\n",
       "       [692547.4 ],\n",
       "       [692075.4 ],\n",
       "       [691603.25],\n",
       "       [691131.1 ],\n",
       "       [690658.94],\n",
       "       [690186.75],\n",
       "       [689714.75],\n",
       "       [689242.5 ],\n",
       "       [688770.25],\n",
       "       [688298.  ],\n",
       "       [687825.6 ],\n",
       "       [687353.4 ],\n",
       "       [686881.  ],\n",
       "       [686408.6 ],\n",
       "       [685936.1 ],\n",
       "       [685463.75],\n",
       "       [684991.4 ],\n",
       "       [684518.9 ],\n",
       "       [684046.5 ],\n",
       "       [683573.9 ],\n",
       "       [683101.1 ],\n",
       "       [682628.4 ],\n",
       "       [682155.56],\n",
       "       [681682.9 ],\n",
       "       [681210.  ],\n",
       "       [680737.25],\n",
       "       [680264.5 ],\n",
       "       [679791.75],\n",
       "       [679319.  ],\n",
       "       [678846.25],\n",
       "       [678373.44],\n",
       "       [677900.7 ],\n",
       "       [677427.94],\n",
       "       [676955.2 ],\n",
       "       [676482.4 ],\n",
       "       [676009.7 ],\n",
       "       [675536.9 ],\n",
       "       [675064.1 ],\n",
       "       [674591.4 ],\n",
       "       [674118.56],\n",
       "       [673645.8 ],\n",
       "       [673173.  ],\n",
       "       [672700.25],\n",
       "       [672227.5 ],\n",
       "       [671754.7 ],\n",
       "       [671281.9 ],\n",
       "       [670809.  ],\n",
       "       [670336.3 ],\n",
       "       [669863.56],\n",
       "       [669390.7 ],\n",
       "       [668918.  ],\n",
       "       [668445.2 ],\n",
       "       [667972.44],\n",
       "       [667499.56],\n",
       "       [667026.9 ],\n",
       "       [666554.  ],\n",
       "       [666081.2 ],\n",
       "       [665608.5 ],\n",
       "       [665135.6 ],\n",
       "       [664662.94],\n",
       "       [664190.1 ],\n",
       "       [663717.3 ],\n",
       "       [663244.56],\n",
       "       [662771.75],\n",
       "       [662298.9 ],\n",
       "       [661826.1 ],\n",
       "       [661353.4 ],\n",
       "       [660880.56],\n",
       "       [660407.8 ],\n",
       "       [659935.  ],\n",
       "       [659462.25],\n",
       "       [658989.4 ],\n",
       "       [658516.56],\n",
       "       [658043.9 ],\n",
       "       [657571.  ],\n",
       "       [657098.25],\n",
       "       [656625.44],\n",
       "       [656152.6 ],\n",
       "       [655679.8 ],\n",
       "       [655207.06],\n",
       "       [654734.25],\n",
       "       [654261.5 ],\n",
       "       [653788.7 ],\n",
       "       [653315.9 ],\n",
       "       [652843.1 ],\n",
       "       [652370.3 ],\n",
       "       [651897.5 ],\n",
       "       [651424.75],\n",
       "       [650952.  ],\n",
       "       [650479.1 ],\n",
       "       [650006.4 ],\n",
       "       [649533.5 ],\n",
       "       [649060.7 ],\n",
       "       [648587.94],\n",
       "       [648114.94],\n",
       "       [647642.1 ],\n",
       "       [647169.25],\n",
       "       [646696.4 ],\n",
       "       [646223.5 ],\n",
       "       [645750.6 ],\n",
       "       [645277.7 ],\n",
       "       [644804.9 ],\n",
       "       [644331.94],\n",
       "       [643859.06],\n",
       "       [643386.2 ],\n",
       "       [642913.3 ],\n",
       "       [642440.4 ],\n",
       "       [641967.5 ],\n",
       "       [641494.6 ],\n",
       "       [641021.75],\n",
       "       [640548.9 ],\n",
       "       [640076.  ],\n",
       "       [639603.1 ],\n",
       "       [639130.25],\n",
       "       [638657.3 ],\n",
       "       [638184.44],\n",
       "       [637711.5 ],\n",
       "       [637238.6 ],\n",
       "       [636765.8 ],\n",
       "       [636292.94],\n",
       "       [635820.  ],\n",
       "       [635347.1 ],\n",
       "       [634874.25],\n",
       "       [634401.4 ],\n",
       "       [633928.5 ],\n",
       "       [633455.6 ],\n",
       "       [632982.75],\n",
       "       [632509.8 ],\n",
       "       [632036.94],\n",
       "       [631564.  ],\n",
       "       [631091.1 ],\n",
       "       [630618.25],\n",
       "       [630145.3 ],\n",
       "       [629672.44],\n",
       "       [629199.5 ],\n",
       "       [628726.6 ],\n",
       "       [628253.75],\n",
       "       [627780.9 ],\n",
       "       [627307.94],\n",
       "       [626835.  ],\n",
       "       [626362.2 ],\n",
       "       [625889.25],\n",
       "       [625416.4 ],\n",
       "       [624943.5 ],\n",
       "       [624470.56],\n",
       "       [623997.6 ],\n",
       "       [623524.75],\n",
       "       [623051.9 ],\n",
       "       [622578.94],\n",
       "       [622106.06],\n",
       "       [621633.1 ],\n",
       "       [621160.25],\n",
       "       [620687.4 ],\n",
       "       [620214.4 ],\n",
       "       [619741.56],\n",
       "       [619268.6 ],\n",
       "       [618795.75],\n",
       "       [618322.9 ],\n",
       "       [617850.  ],\n",
       "       [617377.  ],\n",
       "       [616904.2 ],\n",
       "       [616431.25],\n",
       "       [615958.3 ],\n",
       "       [615485.44],\n",
       "       [615012.5 ],\n",
       "       [614539.7 ],\n",
       "       [614066.7 ],\n",
       "       [613593.9 ],\n",
       "       [613120.9 ],\n",
       "       [612648.  ],\n",
       "       [612175.1 ],\n",
       "       [611702.25],\n",
       "       [611229.4 ],\n",
       "       [610756.44],\n",
       "       [610283.5 ],\n",
       "       [609810.6 ],\n",
       "       [609337.75],\n",
       "       [608864.8 ],\n",
       "       [608391.94],\n",
       "       [607919.  ],\n",
       "       [607446.06],\n",
       "       [606973.25],\n",
       "       [606500.25],\n",
       "       [606027.4 ],\n",
       "       [605554.5 ],\n",
       "       [605081.56],\n",
       "       [604608.6 ],\n",
       "       [604135.75],\n",
       "       [603662.8 ],\n",
       "       [603190.  ],\n",
       "       [602717.1 ],\n",
       "       [602244.2 ],\n",
       "       [601771.3 ],\n",
       "       [601298.44],\n",
       "       [600825.5 ],\n",
       "       [600352.6 ],\n",
       "       [599879.75],\n",
       "       [599406.9 ],\n",
       "       [598933.94],\n",
       "       [598461.06],\n",
       "       [597988.2 ],\n",
       "       [597515.3 ],\n",
       "       [597042.4 ],\n",
       "       [596569.5 ],\n",
       "       [596096.5 ],\n",
       "       [595623.7 ],\n",
       "       [595150.75],\n",
       "       [594677.6 ],\n",
       "       [594204.5 ],\n",
       "       [593731.4 ],\n",
       "       [593258.25],\n",
       "       [592781.56],\n",
       "       [592303.06],\n",
       "       [591824.5 ],\n",
       "       [591346.  ],\n",
       "       [590867.56],\n",
       "       [590389.  ],\n",
       "       [589910.5 ],\n",
       "       [589432.06],\n",
       "       [588953.5 ],\n",
       "       [588475.06],\n",
       "       [587996.44],\n",
       "       [587518.  ],\n",
       "       [587039.44],\n",
       "       [586561.  ],\n",
       "       [586082.5 ],\n",
       "       [585603.94],\n",
       "       [585125.44],\n",
       "       [584646.94],\n",
       "       [584168.5 ],\n",
       "       [583690.  ],\n",
       "       [583211.5 ],\n",
       "       [582733.  ],\n",
       "       [582254.5 ],\n",
       "       [581776.06],\n",
       "       [581297.56],\n",
       "       [580819.06],\n",
       "       [580340.5 ],\n",
       "       [579862.06],\n",
       "       [579383.56],\n",
       "       [578905.1 ],\n",
       "       [578426.6 ],\n",
       "       [577948.06],\n",
       "       [577469.56],\n",
       "       [576991.06],\n",
       "       [576512.6 ],\n",
       "       [576034.06],\n",
       "       [575555.5 ],\n",
       "       [575077.1 ],\n",
       "       [574598.56],\n",
       "       [574120.06],\n",
       "       [573641.5 ],\n",
       "       [573163.06],\n",
       "       [572684.5 ],\n",
       "       [572206.06],\n",
       "       [571727.56],\n",
       "       [571249.  ],\n",
       "       [570770.56],\n",
       "       [570292.  ],\n",
       "       [569813.5 ],\n",
       "       [569335.06],\n",
       "       [568856.5 ],\n",
       "       [568378.  ],\n",
       "       [567899.44],\n",
       "       [567421.  ],\n",
       "       [566942.44],\n",
       "       [566464.  ],\n",
       "       [565985.4 ],\n",
       "       [565506.6 ],\n",
       "       [565027.75],\n",
       "       [564549.  ],\n",
       "       [564070.2 ],\n",
       "       [563591.5 ],\n",
       "       [563112.6 ],\n",
       "       [562633.9 ],\n",
       "       [562155.06],\n",
       "       [561676.3 ],\n",
       "       [561197.5 ],\n",
       "       [560718.6 ],\n",
       "       [560239.9 ],\n",
       "       [559761.1 ],\n",
       "       [559282.4 ],\n",
       "       [558803.56],\n",
       "       [558324.75],\n",
       "       [557846.  ],\n",
       "       [557367.2 ],\n",
       "       [556888.4 ],\n",
       "       [556409.6 ],\n",
       "       [555930.8 ],\n",
       "       [555452.  ],\n",
       "       [554973.2 ],\n",
       "       [554494.4 ],\n",
       "       [554015.6 ],\n",
       "       [553536.8 ],\n",
       "       [553058.  ],\n",
       "       [552579.25],\n",
       "       [552100.44],\n",
       "       [551621.6 ],\n",
       "       [551142.9 ],\n",
       "       [550664.06],\n",
       "       [550185.25],\n",
       "       [549706.44],\n",
       "       [549227.6 ],\n",
       "       [548748.9 ],\n",
       "       [548270.06],\n",
       "       [547791.25],\n",
       "       [547312.44],\n",
       "       [546833.75],\n",
       "       [546354.9 ],\n",
       "       [545876.06],\n",
       "       [545397.3 ],\n",
       "       [544918.5 ],\n",
       "       [544439.75],\n",
       "       [543960.9 ],\n",
       "       [543482.1 ],\n",
       "       [543003.3 ],\n",
       "       [542524.56],\n",
       "       [542045.7 ],\n",
       "       [541566.9 ],\n",
       "       [541088.1 ],\n",
       "       [540609.3 ],\n",
       "       [540130.5 ],\n",
       "       [539651.75],\n",
       "       [539172.9 ],\n",
       "       [538694.1 ],\n",
       "       [538215.3 ],\n",
       "       [537736.5 ],\n",
       "       [537257.75],\n",
       "       [536778.94],\n",
       "       [536300.1 ],\n",
       "       [535821.3 ],\n",
       "       [535342.56],\n",
       "       [534863.7 ],\n",
       "       [534384.94],\n",
       "       [533906.2 ],\n",
       "       [533427.44],\n",
       "       [532948.7 ],\n",
       "       [532469.94],\n",
       "       [531991.2 ],\n",
       "       [531512.5 ],\n",
       "       [531033.7 ],\n",
       "       [530555.  ],\n",
       "       [530076.2 ],\n",
       "       [529597.5 ],\n",
       "       [529118.7 ],\n",
       "       [528640.  ],\n",
       "       [528161.2 ],\n",
       "       [527682.44],\n",
       "       [527203.75],\n",
       "       [526724.94],\n",
       "       [526246.1 ],\n",
       "       [525767.44],\n",
       "       [525288.6 ],\n",
       "       [524809.94],\n",
       "       [524331.2 ],\n",
       "       [523852.44],\n",
       "       [523373.7 ],\n",
       "       [522894.9 ],\n",
       "       [522416.12],\n",
       "       [521937.44],\n",
       "       [521458.7 ],\n",
       "       [520979.88],\n",
       "       [520501.12],\n",
       "       [520022.38],\n",
       "       [519543.62],\n",
       "       [519064.88],\n",
       "       [518586.1 ],\n",
       "       [518107.38],\n",
       "       [517628.6 ],\n",
       "       [517149.8 ],\n",
       "       [516671.06],\n",
       "       [516192.3 ],\n",
       "       [515713.53],\n",
       "       [515234.75],\n",
       "       [514756.  ],\n",
       "       [514277.2 ],\n",
       "       [513798.47],\n",
       "       [513319.7 ],\n",
       "       [512840.94],\n",
       "       [512362.16],\n",
       "       [511883.38],\n",
       "       [511404.62],\n",
       "       [510925.9 ],\n",
       "       [510447.1 ],\n",
       "       [509968.38],\n",
       "       [509489.56],\n",
       "       [509010.8 ],\n",
       "       [508532.06],\n",
       "       [508053.25],\n",
       "       [507574.5 ],\n",
       "       [507095.75],\n",
       "       [506616.9 ],\n",
       "       [506138.12],\n",
       "       [505659.44],\n",
       "       [505180.66],\n",
       "       [504701.88],\n",
       "       [504223.1 ],\n",
       "       [503744.34],\n",
       "       [503265.6 ],\n",
       "       [502786.84],\n",
       "       [502308.  ],\n",
       "       [501829.3 ],\n",
       "       [501350.5 ],\n",
       "       [500871.75],\n",
       "       [500392.94],\n",
       "       [499914.22],\n",
       "       [499435.44],\n",
       "       [498956.53],\n",
       "       [498477.53],\n",
       "       [497998.7 ],\n",
       "       [497519.7 ],\n",
       "       [497040.75],\n",
       "       [496561.8 ],\n",
       "       [496082.8 ],\n",
       "       [495603.84],\n",
       "       [495124.9 ],\n",
       "       [494645.97],\n",
       "       [494167.06],\n",
       "       [493688.1 ],\n",
       "       [493209.1 ],\n",
       "       [492729.12],\n",
       "       [492248.62],\n",
       "       [491768.1 ],\n",
       "       [491287.53],\n",
       "       [490806.94],\n",
       "       [490326.4 ],\n",
       "       [489845.84],\n",
       "       [489365.28],\n",
       "       [488884.7 ],\n",
       "       [488404.12],\n",
       "       [487923.6 ],\n",
       "       [487443.03],\n",
       "       [486962.5 ],\n",
       "       [486481.88],\n",
       "       [486001.38],\n",
       "       [485520.88],\n",
       "       [485040.25],\n",
       "       [484559.72],\n",
       "       [484079.16],\n",
       "       [483598.56],\n",
       "       [483118.03],\n",
       "       [482637.44],\n",
       "       [482156.84],\n",
       "       [481676.3 ],\n",
       "       [481195.75],\n",
       "       [480715.22],\n",
       "       [480234.6 ],\n",
       "       [479754.06],\n",
       "       [479273.47],\n",
       "       [478792.88],\n",
       "       [478312.3 ],\n",
       "       [477831.75],\n",
       "       [477351.22],\n",
       "       [476870.62],\n",
       "       [476390.  ],\n",
       "       [475909.5 ],\n",
       "       [475428.94],\n",
       "       [474948.3 ],\n",
       "       [474467.7 ],\n",
       "       [473987.16],\n",
       "       [473506.62],\n",
       "       [473026.03],\n",
       "       [472545.5 ],\n",
       "       [472064.88],\n",
       "       [471584.3 ],\n",
       "       [471103.72],\n",
       "       [470623.1 ],\n",
       "       [470142.53],\n",
       "       [469662.  ],\n",
       "       [469181.4 ],\n",
       "       [468700.84],\n",
       "       [468220.25],\n",
       "       [467739.7 ],\n",
       "       [467259.12],\n",
       "       [466778.53],\n",
       "       [466297.94],\n",
       "       [465817.38],\n",
       "       [465336.78],\n",
       "       [464856.22],\n",
       "       [464375.62],\n",
       "       [463895.06],\n",
       "       [463414.44],\n",
       "       [462933.9 ],\n",
       "       [462453.3 ],\n",
       "       [461972.8 ],\n",
       "       [461492.84],\n",
       "       [461012.88],\n",
       "       [460533.  ],\n",
       "       [460053.12],\n",
       "       [459573.34],\n",
       "       [459093.53],\n",
       "       [458613.62],\n",
       "       [458133.88],\n",
       "       [457654.  ],\n",
       "       [457174.2 ],\n",
       "       [456694.38],\n",
       "       [456214.53],\n",
       "       [455734.75],\n",
       "       [455254.94],\n",
       "       [454775.06],\n",
       "       [454295.25],\n",
       "       [453815.4 ],\n",
       "       [453335.56],\n",
       "       [452855.75],\n",
       "       [452375.94],\n",
       "       [451896.06],\n",
       "       [451416.25],\n",
       "       [450936.44],\n",
       "       [450456.56],\n",
       "       [449976.8 ],\n",
       "       [449496.94],\n",
       "       [449017.06],\n",
       "       [448537.22],\n",
       "       [448057.38],\n",
       "       [447577.56],\n",
       "       [447097.7 ],\n",
       "       [446617.88],\n",
       "       [446143.7 ],\n",
       "       [445676.8 ],\n",
       "       [445209.06],\n",
       "       [444740.88],\n",
       "       [444272.66],\n",
       "       [443804.44],\n",
       "       [443336.28],\n",
       "       [442868.12],\n",
       "       [442399.88],\n",
       "       [441931.7 ],\n",
       "       [441463.47],\n",
       "       [440995.3 ],\n",
       "       [440527.06],\n",
       "       [440058.88],\n",
       "       [439589.5 ],\n",
       "       [439119.06],\n",
       "       [438648.62],\n",
       "       [438178.2 ],\n",
       "       [437735.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Cycles'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-e617260db8f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_eva\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cycles'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\praneeth_pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mc:\\users\\praneeth_pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3111\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\praneeth_pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\praneeth_pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4404\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Cycles'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_eva = train.drop(['Cycles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.evaluate(test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maxi Prin Strs</th>\n",
       "      <th>Mini Prin Strs</th>\n",
       "      <th>Sa</th>\n",
       "      <th>Sm</th>\n",
       "      <th>Sn'</th>\n",
       "      <th>Sn</th>\n",
       "      <th>b</th>\n",
       "      <th>b'</th>\n",
       "      <th>N'</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-72920.0</td>\n",
       "      <td>-325100.0</td>\n",
       "      <td>126144.25</td>\n",
       "      <td>-198955.75</td>\n",
       "      <td>262.783882</td>\n",
       "      <td>480.030393</td>\n",
       "      <td>-0.840361</td>\n",
       "      <td>-1.189964</td>\n",
       "      <td>1.263238</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-72811.5</td>\n",
       "      <td>-324964.5</td>\n",
       "      <td>126130.75</td>\n",
       "      <td>-198833.75</td>\n",
       "      <td>262.623355</td>\n",
       "      <td>480.272403</td>\n",
       "      <td>-0.840346</td>\n",
       "      <td>-1.189986</td>\n",
       "      <td>1.263875</td>\n",
       "      <td>0.756787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-72703.0</td>\n",
       "      <td>-324829.0</td>\n",
       "      <td>126117.25</td>\n",
       "      <td>-198711.75</td>\n",
       "      <td>262.462829</td>\n",
       "      <td>480.514709</td>\n",
       "      <td>-0.840330</td>\n",
       "      <td>-1.190008</td>\n",
       "      <td>1.264512</td>\n",
       "      <td>0.756329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-72594.5</td>\n",
       "      <td>-324693.5</td>\n",
       "      <td>126103.75</td>\n",
       "      <td>-198589.75</td>\n",
       "      <td>262.302303</td>\n",
       "      <td>480.757312</td>\n",
       "      <td>-0.840315</td>\n",
       "      <td>-1.190030</td>\n",
       "      <td>1.265151</td>\n",
       "      <td>0.755871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-72486.0</td>\n",
       "      <td>-324558.0</td>\n",
       "      <td>126090.25</td>\n",
       "      <td>-198467.75</td>\n",
       "      <td>262.141776</td>\n",
       "      <td>481.000212</td>\n",
       "      <td>-0.840299</td>\n",
       "      <td>-1.190052</td>\n",
       "      <td>1.265790</td>\n",
       "      <td>0.755413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maxi Prin Strs  Mini Prin Strs         Sa         Sm         Sn'  \\\n",
       "0        -72920.0       -325100.0  126144.25 -198955.75  262.783882   \n",
       "1        -72811.5       -324964.5  126130.75 -198833.75  262.623355   \n",
       "2        -72703.0       -324829.0  126117.25 -198711.75  262.462829   \n",
       "3        -72594.5       -324693.5  126103.75 -198589.75  262.302303   \n",
       "4        -72486.0       -324558.0  126090.25 -198467.75  262.141776   \n",
       "\n",
       "           Sn         b        b'        N'         N  \n",
       "0  480.030393 -0.840361 -1.189964  1.263238  0.757245  \n",
       "1  480.272403 -0.840346 -1.189986  1.263875  0.756787  \n",
       "2  480.514709 -0.840330 -1.190008  1.264512  0.756329  \n",
       "3  480.757312 -0.840315 -1.190030  1.265151  0.755871  \n",
       "4  481.000212 -0.840299 -1.190052  1.265790  0.755413  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Cycles'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maxi Prin Strs</th>\n",
       "      <th>Mini Prin Strs</th>\n",
       "      <th>Sa</th>\n",
       "      <th>Sm</th>\n",
       "      <th>Sn'</th>\n",
       "      <th>Sn</th>\n",
       "      <th>b</th>\n",
       "      <th>b'</th>\n",
       "      <th>N'</th>\n",
       "      <th>N</th>\n",
       "      <th>Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-72920.0</td>\n",
       "      <td>-325100.0</td>\n",
       "      <td>126144.25</td>\n",
       "      <td>-198955.75</td>\n",
       "      <td>262.783882</td>\n",
       "      <td>480.030393</td>\n",
       "      <td>-0.840361</td>\n",
       "      <td>-1.189964</td>\n",
       "      <td>1.263238</td>\n",
       "      <td>0.757245</td>\n",
       "      <td>757204.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-72811.5</td>\n",
       "      <td>-324964.5</td>\n",
       "      <td>126130.75</td>\n",
       "      <td>-198833.75</td>\n",
       "      <td>262.623355</td>\n",
       "      <td>480.272403</td>\n",
       "      <td>-0.840346</td>\n",
       "      <td>-1.189986</td>\n",
       "      <td>1.263875</td>\n",
       "      <td>0.756787</td>\n",
       "      <td>756732.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-72703.0</td>\n",
       "      <td>-324829.0</td>\n",
       "      <td>126117.25</td>\n",
       "      <td>-198711.75</td>\n",
       "      <td>262.462829</td>\n",
       "      <td>480.514709</td>\n",
       "      <td>-0.840330</td>\n",
       "      <td>-1.190008</td>\n",
       "      <td>1.264512</td>\n",
       "      <td>0.756329</td>\n",
       "      <td>756261.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-72594.5</td>\n",
       "      <td>-324693.5</td>\n",
       "      <td>126103.75</td>\n",
       "      <td>-198589.75</td>\n",
       "      <td>262.302303</td>\n",
       "      <td>480.757312</td>\n",
       "      <td>-0.840315</td>\n",
       "      <td>-1.190030</td>\n",
       "      <td>1.265151</td>\n",
       "      <td>0.755871</td>\n",
       "      <td>755788.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-72486.0</td>\n",
       "      <td>-324558.0</td>\n",
       "      <td>126090.25</td>\n",
       "      <td>-198467.75</td>\n",
       "      <td>262.141776</td>\n",
       "      <td>481.000212</td>\n",
       "      <td>-0.840299</td>\n",
       "      <td>-1.190052</td>\n",
       "      <td>1.265790</td>\n",
       "      <td>0.755413</td>\n",
       "      <td>755317.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maxi Prin Strs  Mini Prin Strs         Sa         Sm         Sn'  \\\n",
       "0        -72920.0       -325100.0  126144.25 -198955.75  262.783882   \n",
       "1        -72811.5       -324964.5  126130.75 -198833.75  262.623355   \n",
       "2        -72703.0       -324829.0  126117.25 -198711.75  262.462829   \n",
       "3        -72594.5       -324693.5  126103.75 -198589.75  262.302303   \n",
       "4        -72486.0       -324558.0  126090.25 -198467.75  262.141776   \n",
       "\n",
       "           Sn         b        b'        N'         N       Cycles  \n",
       "0  480.030393 -0.840361 -1.189964  1.263238  0.757245  757204.8750  \n",
       "1  480.272403 -0.840346 -1.189986  1.263875  0.756787  756732.8750  \n",
       "2  480.514709 -0.840330 -1.190008  1.264512  0.756329  756261.0000  \n",
       "3  480.757312 -0.840315 -1.190030  1.265151  0.755871  755788.9375  \n",
       "4  481.000212 -0.840299 -1.190052  1.265790  0.755413  755317.0625  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the new file as ANN.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('ANN_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "#import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "#plot_model(NN_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(NN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(NN_model, title=\"Pierce punch prediction neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = train['Cycles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'line'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9260cd76876c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'line'"
     ]
    }
   ],
   "source": [
    "plt.line(predictions,act)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
